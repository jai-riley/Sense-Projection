{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simalign\n",
      "  Downloading simalign-0.4-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from simalign) (1.26.2)\n",
      "Requirement already satisfied: torch in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from simalign) (1.10.2)\n",
      "Requirement already satisfied: scipy in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from simalign) (1.7.1)\n",
      "Requirement already satisfied: transformers in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from simalign) (4.34.1)\n",
      "Requirement already satisfied: regex in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from simalign) (2023.10.3)\n",
      "Requirement already satisfied: networkx in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from simalign) (2.6.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from simalign) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from scikit-learn->simalign) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from scikit-learn->simalign) (2.2.0)\n",
      "Collecting numpy (from simalign)\n",
      "  Downloading numpy-1.22.4-cp39-cp39-macosx_10_15_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from torch->simalign) (4.8.0)\n",
      "Requirement already satisfied: filelock in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers->simalign) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers->simalign) (0.17.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers->simalign) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers->simalign) (5.3.1)\n",
      "Requirement already satisfied: requests in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers->simalign) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers->simalign) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers->simalign) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers->simalign) (4.62.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers->simalign) (2023.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->transformers->simalign) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->transformers->simalign) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->transformers->simalign) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->transformers->simalign) (2023.11.17)\n",
      "Downloading simalign-0.4-py3-none-any.whl (8.1 kB)\n",
      "Downloading numpy-1.22.4-cp39-cp39-macosx_10_15_x86_64.whl (17.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.7/17.7 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, simalign\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.2\n",
      "    Uninstalling numpy-1.26.2:\n",
      "      Successfully uninstalled numpy-1.26.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.22.4 which is incompatible.\n",
      "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.22.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.22.4 simalign-0.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install hanlp\n",
    "!pip install simalign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb406a76c0f6d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:03:07.734747Z",
     "start_time": "2024-09-14T08:03:01.773665Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, csv\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from simalign import SentenceAligner\n",
    "# from google.cloud import translate_v2 as translate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612df192",
   "metadata": {},
   "source": [
    "Below is a working example using the provided data files.\n",
    "To align Italian and Spanish to English, using the files in the 'second-sense' folder. Otherwise, use the files in the 'Original' folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b13fc3dfe5421d25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:47.113938Z",
     "start_time": "2024-09-14T08:05:47.070873Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "src_lan = 'en'\n",
    "# target language\n",
    "tgt_lan = 'BN'\n",
    "language = \"Bengali\"\n",
    "\n",
    "RESOURCE = '~/Desktop/Research/Sense-Projection'\n",
    "DATA =  RESOURCE+'/data/'+language\n",
    "TRANS_FILE = os.path.join(DATA, 'trans-sentences-'+language+'.tsv')\n",
    "TOKENS_FILE = os.path.join(DATA, language+'-Gold.tsv')\n",
    "ALIGN_SENT_FILE = os.path.join(DATA, 'sentences-aligned-'+language+'.tsv')\n",
    "ALIGN_TOKEN_FILE = os.path.join(DATA, 'tokens-aligned-'+language+'.tsv')\n",
    "\n",
    "# DATA = os.path.join(RESOURCE, 'data')\n",
    "DATA =  RESOURCE+'/data/English/Original/'\n",
    "\n",
    "KEY = os.path.join(RESOURCE, 'key')\n",
    "RAW_SENSE_TSV = os.path.join(DATA, 'gold-tokens-English-wSenses.tsv')\n",
    "RAW_SENTENCE_TSV = os.path.join(DATA, 'gold-sentences-English-full.tsv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c6865ff265fa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T00:25:20.160408Z",
     "start_time": "2024-07-20T00:25:20.081626Z"
    },
    "collapsed": false
   },
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b00d2748a93fc3cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:47.469676Z",
     "start_time": "2024-09-14T08:05:47.430137Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>BN Synset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d001.s001.t001</td>\n",
       "      <td>This</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d001.s001.t002</td>\n",
       "      <td>document</td>\n",
       "      <td>document</td>\n",
       "      <td>N</td>\n",
       "      <td>bn:00028015n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d001.s001.t003</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d001.s001.t004</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d001.s001.t005</td>\n",
       "      <td>summary</td>\n",
       "      <td>summary</td>\n",
       "      <td>N</td>\n",
       "      <td>bn:00075142n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token ID     Token     Lemma POS     BN Synset\n",
       "0  d001.s001.t001      This       NaN   X           NaN\n",
       "1  d001.s001.t002  document  document   N  bn:00028015n\n",
       "2  d001.s001.t003        is        be   V           NaN\n",
       "3  d001.s001.t004         a       NaN   X           NaN\n",
       "4  d001.s001.t005   summary   summary   N  bn:00075142n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw\n",
    "raw_sense_df = pd.read_csv(RAW_SENSE_TSV, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "raw_sense_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f042be62c8de0a8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:47.706594Z",
     "start_time": "2024-09-14T08:05:47.681398Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df = pd.read_csv(RAW_SENTENCE_TSV, delimiter='\\t',  quoting=csv.QUOTE_NONE)\n",
    "sentence_df.head()\n",
    "sents = sentence_df[\"ID\"].tolist()\n",
    "len(sents)\n",
    "# print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a52ea439706c5fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:47.816258Z",
     "start_time": "2024-09-14T08:05:47.808935Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n"
     ]
    }
   ],
   "source": [
    "sids = sentence_df[\"ID\"].tolist()\n",
    "# sids = [i.replace('d', 'i') for i in sids]\n",
    "# sids[:4]\n",
    "print(len(sids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86ef027023e515d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:48.052992Z",
     "start_time": "2024-09-14T08:05:48.028191Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>English</th>\n",
       "      <th>Bengali Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d001.s001</td>\n",
       "      <td>This document is a summary of the European Pub...</td>\n",
       "      <td>এই নথিটি ইউরোপীয় পাবলিক অ্যাসেসমেন্ট রিপোর্ট ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d001.s002</td>\n",
       "      <td>It explains how the Committee for Medicinal Pr...</td>\n",
       "      <td>এটি ব্যাখ্যা করে যে কীভাবে কমিটি ফর মেডিসিনাল ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d001.s003</td>\n",
       "      <td>If you need more information about your medica...</td>\n",
       "      <td>আপনার যদি আপনার চিকিৎসার অবস্থা বা আপনার চিকিত...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d001.s004</td>\n",
       "      <td>If you want more information on the basis of t...</td>\n",
       "      <td>আপনি যদি CHMP সুপারিশের ভিত্তিতে আরও তথ্য চান,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d001.s005</td>\n",
       "      <td>What is Alimta ?</td>\n",
       "      <td>আলিমতা কি?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                            English  \\\n",
       "0  d001.s001  This document is a summary of the European Pub...   \n",
       "1  d001.s002  It explains how the Committee for Medicinal Pr...   \n",
       "2  d001.s003  If you need more information about your medica...   \n",
       "3  d001.s004  If you want more information on the basis of t...   \n",
       "4  d001.s005                                   What is Alimta ?   \n",
       "\n",
       "                                 Bengali Translation  \n",
       "0  এই নথিটি ইউরোপীয় পাবলিক অ্যাসেসমেন্ট রিপোর্ট ...  \n",
       "1  এটি ব্যাখ্যা করে যে কীভাবে কমিটি ফর মেডিসিনাল ...  \n",
       "2  আপনার যদি আপনার চিকিৎসার অবস্থা বা আপনার চিকিত...  \n",
       "3  আপনি যদি CHMP সুপারিশের ভিত্তিতে আরও তথ্য চান,...  \n",
       "4                                         আলিমতা কি?  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_df = pd.read_csv(TRANS_FILE, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f432a89a379c822",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:48.275751Z",
     "start_time": "2024-09-14T08:05:48.215503Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>BN Synset</th>\n",
       "      <th>Gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d001.s001.t001</td>\n",
       "      <td>এই</td>\n",
       "      <td>এই</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d001.s001.t002</td>\n",
       "      <td>নথিটি</td>\n",
       "      <td>নথি</td>\n",
       "      <td>N</td>\n",
       "      <td>bn:00028015n</td>\n",
       "      <td>Writing that provides information (especially ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d001.s001.t003</td>\n",
       "      <td>ইউরোপীয়</td>\n",
       "      <td>ইউরোপ</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d001.s001.t004</td>\n",
       "      <td>পাবলিক</td>\n",
       "      <td>পাবলিক</td>\n",
       "      <td>A</td>\n",
       "      <td>bn:00109211a</td>\n",
       "      <td>Not private; open to or concerning the people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d001.s001.t005</td>\n",
       "      <td>অ্যাসেসমেন্ট</td>\n",
       "      <td>অ্যাসেসমেন্ট</td>\n",
       "      <td>N</td>\n",
       "      <td>bn:00006502n</td>\n",
       "      <td>The act of judging or assessing a person or si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>d002.s020.t022</td>\n",
       "      <td>গণ্য</td>\n",
       "      <td>গণ্য</td>\n",
       "      <td>V</td>\n",
       "      <td>bn:00095141v</td>\n",
       "      <td>Regard or consider in a specific way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>d002.s020.t023</td>\n",
       "      <td>হবে</td>\n",
       "      <td>হবে</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>d002.s020.t024</td>\n",
       "      <td>।</td>\n",
       "      <td>।</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>d002.s021.t001</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>d002.s021.t002</td>\n",
       "      <td>#ERROR!</td>\n",
       "      <td>#ERROR!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Token ID         Token         Lemma  POS     BN Synset  \\\n",
       "0    d001.s001.t001            এই            এই    X           NaN   \n",
       "1    d001.s001.t002         নথিটি           নথি    N  bn:00028015n   \n",
       "2    d001.s001.t003      ইউরোপীয়         ইউরোপ    N           NaN   \n",
       "3    d001.s001.t004        পাবলিক        পাবলিক    A  bn:00109211a   \n",
       "4    d001.s001.t005  অ্যাসেসমেন্ট  অ্যাসেসমেন্ট    N  bn:00006502n   \n",
       "..              ...           ...           ...  ...           ...   \n",
       "995  d002.s020.t022          গণ্য          গণ্য    V  bn:00095141v   \n",
       "996  d002.s020.t023           হবে           হবে    V           NaN   \n",
       "997  d002.s020.t024             ।             ।    X           NaN   \n",
       "998  d002.s021.t001             :             :    X           NaN   \n",
       "999  d002.s021.t002       #ERROR!       #ERROR!  NaN           NaN   \n",
       "\n",
       "                                                 Gloss  \n",
       "0                                                  NaN  \n",
       "1    Writing that provides information (especially ...  \n",
       "2                                                  NaN  \n",
       "3    Not private; open to or concerning the people ...  \n",
       "4    The act of judging or assessing a person or si...  \n",
       "..                                                 ...  \n",
       "995               Regard or consider in a specific way  \n",
       "996                                                NaN  \n",
       "997                                                NaN  \n",
       "998                                                NaN  \n",
       "999                                                NaN  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkns_df = pd.read_csv(TOKENS_FILE, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "tkns_df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "657283dde5c279c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:48.520729Z",
     "start_time": "2024-09-14T08:05:48.427681Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2287"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_tkns = tkns_df['Token'].tolist()\n",
    "len(tgt_tkns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c7b3b3697f3f04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T00:25:29.100491Z",
     "start_time": "2024-07-20T00:25:29.088726Z"
    },
    "collapsed": false
   },
   "source": [
    "# ALIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bfcface1251e192",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:57.634596Z",
     "start_time": "2024-09-14T08:05:48.993979Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 14:13:04,649 - simalign.simalign - INFO - Initialized the EmbeddingLoader with model: xlm-roberta-base\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "layer = 8\n",
    "# \"bert\": \"bert-base-multilingual-cased\",\n",
    "# \"xlmr\": \"xlm-roberta-base\"\n",
    "model = 'xlmr'\n",
    "# mwmf (Match), inter (ArgMax), itermax (IterMax)\n",
    "mode = 'inter'\n",
    "matching_methods = 'mai'\n",
    "token_type='bpe'\n",
    "aligner = SentenceAligner(\n",
    "    model=model\n",
    "    , token_type=token_type\n",
    "    , matching_methods=matching_methods\n",
    "    , layer=layer\n",
    "    , device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5963d6746fecc939",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:57.652105Z",
     "start_time": "2024-09-14T08:05:57.639785Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>BN Synset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d001.s001.t001</td>\n",
       "      <td>This</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d001.s001.t002</td>\n",
       "      <td>document</td>\n",
       "      <td>document</td>\n",
       "      <td>N</td>\n",
       "      <td>bn:00028015n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d001.s001.t003</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d001.s001.t004</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d001.s001.t005</td>\n",
       "      <td>summary</td>\n",
       "      <td>summary</td>\n",
       "      <td>N</td>\n",
       "      <td>bn:00075142n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token ID     Token     Lemma POS     BN Synset\n",
       "0  d001.s001.t001      This       NaN   X           NaN\n",
       "1  d001.s001.t002  document  document   N  bn:00028015n\n",
       "2  d001.s001.t003        is        be   V           NaN\n",
       "3  d001.s001.t004         a       NaN   X           NaN\n",
       "4  d001.s001.t005   summary   summary   N  bn:00075142n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_sense_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55570ec",
   "metadata": {},
   "source": [
    "Run the below cell only if using the files in the English/Original directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb827932bd9b23f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:57.687254Z",
     "start_time": "2024-09-14T08:05:57.648963Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['This', 'document', 'is', 'a', 'summary', 'of', 'the', 'European', 'Public', 'Assessment', 'Report', '(', 'EPAR', ')', '.']\n",
      "['It', 'explains', 'how', 'the', 'Committee', 'for', 'Medicinal', 'Products', 'for', 'Human', 'Use', '(', 'CHMP', ')', 'assessed', 'the', 'studies', 'performed', ',', 'to', 'reach', 'their', 'recommendations', 'on', 'how', 'to', 'use', 'the', 'medicine', '.']\n",
      "['If', 'you', 'need', 'more', 'information', 'about', 'your', 'medical', 'condition', 'or', 'your', 'treatment', ',', 'read', 'the', 'Package', 'Leaflet', '(', 'also', 'part', 'of', 'the', 'EPAR', ')', 'or', 'contact', 'your', 'doctor', 'or', 'pharmacist', '.']\n",
      "['If', 'you', 'want', 'more', 'information', 'on', 'the', 'basis', 'of', 'the', 'CHMP', 'recommendations', ',', 'read', 'the', 'Scientific', 'Discussion', '(', 'also', 'part', 'of', 'the', 'EPAR', ')', '.']\n",
      "['What', 'is', 'Alimta', '?']\n",
      "['Alimta', 'is', 'a', 'powder', 'that', 'is', 'made up', 'into', 'a', 'solution', 'for', 'infusion', '(', 'drip', 'into', 'a', 'vein', ')', '.']\n",
      "['It', 'contains', 'the', 'active', 'substance', 'pemetrexed', '.']\n",
      "['What', 'is', 'Alimta', 'used', 'for', '?']\n",
      "['Alimta', 'is', 'used', 'to', 'treat', 'two', 'types', 'of', 'cancer', ':', 'pleural', 'mesothelioma', '(', 'cancer', 'of', 'the', 'lining', 'of', 'the', 'lungs', 'that', 'is', 'usually', 'caused', 'by', 'exposure', 'to', 'asbestos', ')', '.']\n",
      "['Alimta', 'is', 'used', 'together', 'with', 'cisplatin', '(', 'another', 'anticancer', 'medicine', ')', 'when', 'the', 'cancer', 'is', 'unresectable', '(', 'cannot', 'be', 'removed', 'by', 'surgery', 'alone', ')', 'and', 'malignant', '(', 'has', 'spread', ',', 'or', 'is', 'likely', 'to', 'spread', 'easily', ',', 'to', 'other', 'parts', 'of', 'the', 'body', ')', ',', 'in', 'patients', 'who', 'have', 'not', 'received', 'chemotherapy', '(', 'medicines', 'for', 'cancer', ')', 'before', 'advanced', 'or', 'metastatic', 'non-small', 'cell', 'lung', 'cancer', 'that', 'is', 'not', 'affecting', 'the', 'squamous', 'cells', '.']\n",
      "['Alimta', 'is', 'used', 'in', 'combination', 'with', 'cisplatin', 'in', 'patients', 'who', 'have', 'not', 'been', 'treated', 'before', ',', 'and', 'on', 'its', 'own', 'in', 'patients', 'who', 'have', 'received', 'another', 'type', 'of', 'chemotherapy', 'in', 'the', 'past', '.']\n",
      "['The', 'medicine', 'can', 'only', 'be', 'obtained', 'with', 'a', 'prescription', '.']\n",
      "['How', 'is', 'Alimta', 'used', '?']\n",
      "['Alimta', 'should', 'only', 'be', 'given', 'under', 'the', 'supervision', 'of', 'a', 'doctor', 'who', 'is', 'qualified', 'in', 'the', 'use', 'of', 'anticancer', 'chemotherapy', '.']\n",
      "['The', 'recommended', 'dose', 'of', 'Alimta', 'is', '500', 'mg', 'per', 'square', 'metre', 'of', 'body', 'surface', 'area', '(', 'calculated', 'using', 'the', 'patient', 's', 'height', 'and', 'weight', ')', '.']\n",
      "['To', 'reduce', 'side', 'effects', ',', 'patients', 'should', 'take', 'a', 'corticosteroid', 'and', 'folic', 'acid', '(', 'a', 'type', 'of', 'vitamin', ')', ',', 'and', 'receive', 'injections', 'of', 'vitamin', 'B12', 'during', 'treatment', 'with', 'Alimta', '.']\n",
      "['When', 'Alimta', 'is', 'given', 'with', 'cisplatin', ',', 'an', 'anti-emetic', 'medicine', '(', 'to', 'prevent', 'vomiting', ')', 'and', 'fluids', '(', 'to', 'prevent', 'dehydration', ')', 'should', 'also', 'be', 'given', 'before', 'or', 'after', 'the', 'cisplatin', 'dose', '.']\n",
      "['Treatment', 'should', 'be', 'delayed', 'or', 'discontinued', ',', 'or', 'the', 'dose', 'reduced', ',', 'in', 'patients', 'whose', 'blood', 'counts', 'are', 'abnormal', 'or', 'who', 'have', 'certain', 'other', 'side', 'effects', '.']\n",
      "['Alimta', 'is', 'not', 'recommended', 'for', 'use', 'in', 'patients', 'with', 'moderate', 'or', 'severe', 'kidney', 'problems', '.']\n",
      "['For', 'more', 'information', ',', 'see', 'the', 'Summary', 'of', 'Product', 'Characteristics', '(', 'also', 'part', 'of', 'the', 'EPAR', ')', '.']\n",
      "['How', 'does', 'Alimta', 'work', '?']\n",
      "['The', 'active', 'substance', 'in', 'Alimta', ',', 'pemetrexed', ',', 'is', 'a', 'cytotoxic', 'medicine', '(', 'a', 'medicine', 'that', 'kills', 'cells', 'that', 'are', 'dividing', ',', 'such as', 'cancer', 'cells', ')', ',', 'which', 'belongs', 'to', 'the', 'group', 'antimetabolites', '.']\n",
      "['In', 'the', 'body', ',', 'pemetrexed', 'is', 'converted', 'into', 'an', 'active', 'form', 'that', 'blocks', 'the', 'activity', 'of', 'the', 'enzymes', 'that', 'are', 'involved', 'in', 'producing', 'nucleotides', '(', 'the', 'building blocks', 'of', 'DNA', 'and', 'RNA', ',', 'the', 'genetic', 'material', 'of', 'cells', ')', '.']\n",
      "['How', 'has', 'Alimta', 'been', 'studied', '?']\n",
      "['For', 'the', 'treatment', 'of', 'malignant', 'pleural', 'mesothelioma', ',', 'Alimta', 'has', 'been', 'studied', 'in', 'one', 'main', 'study', 'in', '456', 'patients', 'who', 'had', 'not', 'received', 'chemotherapy', 'for', 'their', 'disease', 'before', '.']\n",
      "['The', 'effects', 'of', 'Alimta', 'in', 'combination', 'with', 'cisplatin', 'were', 'compared', 'with', 'those', 'of', 'cisplatin', 'alone', '.']\n",
      "['For', 'the', 'treatment', 'of', 'non-small', 'cell', 'lung', 'cancer', ',', 'the', 'effects', 'of', 'Alimta', 'were', 'compared', 'with', 'those', 'of', 'docetaxel', '(', 'another', 'anticancer', 'medicine', ')', 'in', 'one', 'study', 'involving', '571', 'patients', 'with', 'locally', 'advanced', 'or', 'metastatic', 'disease', 'who', 'had', 'received', 'chemotherapy', 'in', 'the', 'past', '.']\n",
      "['Alimta', 'was', 'also', 'compared', 'with', 'gemcitabine', '(', 'another', 'anticancer', 'medicine', ')', ',', 'both', 'in', 'combination', 'with', 'cisplatin', ',', 'in', 'a', 'study', 'involving', '1,725', 'patients', 'who', 'had', 'not', 'received', 'chemotherapy', 'for', 'lung', 'cancer', 'in', 'the', 'past', '.']\n",
      "['In', 'all', 'three', 'studies', ',', 'the', 'main', 'measure', 'of', 'effectiveness', 'was', 'how', 'long', 'the', 'patients', 'survived', '.']\n",
      "['What', 'benefit', 'has', 'Alimta', 'shown', 'during', 'the', 'studies', '?']\n",
      "['Alimta', 'increased', 'the', 'survival', 'time', 'of', 'patients', 'with', 'malignant', 'pleural', 'mesothelioma', '.']\n",
      "['Patients', 'receiving', 'Alimta', 'and', 'cisplatin', 'survived', 'for', 'an', 'average', 'of', '12.1', 'months', ',', 'compared', 'with', '9.3', 'months', 'in', 'those', 'receiving', 'cisplatin', 'alone', '.']\n",
      "['In', 'the', 'treatment', 'of', 'patients', 'with', 'non-small', 'cell', 'lung', 'cancer', ',', 'Alimta', 'was', 'as', 'effective', 'as', 'the', 'comparators', '.']\n",
      "['In', 'patients', 'who', 'had', 'received', 'chemotherapy', 'in', 'the', 'past', ',', 'the', 'average', 'survival', 'time', 'was', '8.3', 'months', 'with', 'Alimta', ',', 'compared', 'with', '7.9', 'months', 'with', 'docetaxel', '.']\n",
      "['In', 'patients', 'who', 'had', 'not', 'received', 'chemotherapy', 'in', 'the', 'past', ',', 'the', 'average', 'survival', 'time', 'was', '10.3', 'months', 'in', 'both', 'groups', '.']\n",
      "['However', ',', 'in', 'both', 'studies', ',', 'patients', 'whose', 'cancer', 'was', 'not', 'affecting', 'squamous', 'cells', 'had', 'longer', 'survival', 'times', 'if', 'they', 'received', 'Alimta', 'than', 'if', 'they', 'received', 'the', 'comparator', '.']\n",
      "['In', 'contrast', ',', 'patients', 'whose', 'cancer', 'was', 'affecting', 'squamous', 'cells', 'had', 'shorter', 'survival', 'times', 'if', 'they', 'received', 'Alimta', '.']\n",
      "['kalgebra', 'is', 'a', 'mathematical', 'calculator', 'based', 'on', 'content', 'markup', 'MathML', 'language', '.']\n",
      "['Nowadays', 'it', 'is', 'capable', 'to', 'make', 'simple', 'MathML', 'operations', '(', 'arithmetic', 'and', 'logical', ')', 'and', 'to', 'representate', '2D', 'and', '3D', 'graphs', '.']\n",
      "['It', 'is', 'actually', 'not', 'necessary', 'to', 'know', 'MathML', 'to', 'use', 'kalgebra', '.']\n",
      "['kalgebra', 'is', 'a', 'MathML', 'based', 'graph', 'calculator', '.']\n",
      "['Although', 'it', 'was', 'initially', 'MathML', 'oriented', 'it', 'can', 'now', 'be', 'used', 'by', 'everyone', 'with', 'little', 'mathematical', 'knowledge', '.']\n",
      "['Here', \"'s\", 'a', 'screenshot', 'of', 'kalgebra', 'main', 'window']\n",
      "['kalgebra', 'main', 'window']\n",
      "['kalgebra', 'main', 'window', 'consists', 'in', 'a', 'Console', 'tab', ',', 'a', '2D', 'Graph', 'tab', ',', 'a', '3D', 'Graph', 'tab', 'and', 'a', 'Dictionary', 'tab', '.']\n",
      "['Below', 'these', 'tabs', 'you', 'will', 'find', 'an', 'input', 'field', 'to', 'type', 'your', 'functions', 'or', 'do', 'your', 'calculations', '.']\n",
      "['If', 'we', 'want', 'to', 'understand', 'how', 'it', 'works', ',', 'the', 'best', 'thing', 'we', 'can', 'do', 'is', 'to', 'realize', 'that', 'our', 'input', 'is', 'being', 'converted', 'into', 'MathML', 'although', 'it', 'is', 'not', 'necessary', 'to', 'know', 'MathML', '.']\n",
      "['I', 'have', 'based', 'the', 'syntax', 'basically', 'on', 'common', 'sense', ',', 'it', 'should', 'not', 'be', 'hard', 'for', 'anyone', '.']\n",
      "['I', 've', 'looked', 'closely', 'to', 'maxima', 'and', 'maple', 's', 'syntax', 'so', 'they', 'look', 'very', 'similar', '.']\n",
      "['+', '-', '*', '/', ':', 'Addition', ',', 'subtraction', ',', 'multiplication', 'and', 'division', '.']\n",
      "['^', ',', '**', ':', 'Power', ',', 'you', 'can', 'use', 'them', 'both', '.']\n",
      "['Also', 'it', 'is', 'possible', 'to', 'use', 'the', 'unicode', '²', 'characters', '.']\n",
      "['Powers', 'are', 'one', 'way', 'to', 'make', 'roots', 'too', '.']\n",
      "['-gt', ':', 'It', 's', 'the', 'way', 'to', 'specify', 'the', 'bounded', 'variable', 'in', 'a', 'function', '.']\n",
      "['(', ')', ':', 'It', 'is', 'used', 'to', 'specify', 'a', 'higher', 'priority', '.']\n",
      "['abc(params)', ':', 'When', 'the', 'parser', 'finds', 'a', 'function', ',', 'it', 'checks', 'if', 'abc', 'is', 'an', 'operator', '.']\n",
      "['If', 'it', 'is', ',', 'it', 'will', 'be', 'treated', 'as', 'an', 'operator', ',', 'if', 'it', 'is', 'not', ',', 'it', 'will', 'be', 'treated', 'as', 'a', 'user', 'function', '.']\n",
      "[':', '=', ':', 'It', 'is', 'used', 'to', 'define', 'a', 'variable', 'value', '.']\n",
      "['?', ':', 'Piecewise', 'condition', 'definition', '.']\n",
      "['Piecewise', 'is', 'the', 'way', 'we', 'can', 'define', 'conditional', 'operations', 'in', 'kalgebra', '.']\n",
      "['If', 'we', 'introduce', 'the', 'condition', 'before', 'the', '?', 'it', 'will', 'use', 'this', 'condition', 'only', 'if', 'it', 'is', 'true', ',', 'if', 'it', 'finds', 'a', '?', 'without', 'any', 'condition', ',', 'it', 'will', 'enter', 'in', 'the', 'last', 'instance', '.']\n",
      "['Mainly', 'useful', 'for', 'working', 'with', 'piecewise', '.']\n",
      "['That', 's', 'easy', '.', 'With', 'this', ',', 'we', 'can', 'operate', 'with', 'functions', 'like', 'cos()', ',', 'sin()', ',', 'any', 'other', 'trigonometric', 'functions', ',', 'sum()', 'or', 'product()', '.']\n",
      "['It', 'does', 'not', 'matter', 'what', 'kind', 'it', 'is', '.']\n",
      "['We', 'can', 'use', 'plus()', ',', 'times()', 'and', 'everything', 'which', 'has', 'its', 'operator', '.']\n",
      "['kalgebra', \"'s\", 'console', 'is', 'useful', 'as', 'a', 'calculator', '.']\n",
      "['There', 'you', 'have', 'a', 'list', 'of', 'the', 'declared', 'variables', '.']\n",
      "['By', 'double', 'clicking', 'on', 'them', 'you', 'will', 'see', 'a', 'dialog', 'that', 'lets', 'you', 'change', 'their', 'values', '(', 'just', 'a', 'way', 'to', 'trick', 'the', 'log', ')', '.']\n",
      "['Every', 'time', 'you', 'enter', 'an', 'expression', ',', 'the', '\"\"\"\"', 'ans', '\"\"\"\"', 'variable', 'value', 'will', 'be', 'changed', 'to', 'the', 'last', 'result', '.']\n",
      "['Ctrl', 'N', 'New', 'Window']\n",
      "['Flushes', 'the', 'log', '.']\n",
      "['Ctrl', 'L', 'Load', 'Script']\n",
      "['Executes', 'the', 'instructions', 'in', 'a', 'file', 'sequentially', '.']\n",
      "['Nice', 'if', 'you', 'want', 'to', 'define', 'some', 'libraries', 'or', 'resume', 'some', 'previous', 'work', '.']\n",
      "['Ctrl', 'G', 'Save', 'Script']\n",
      "['Saves', 'the', 'instructions', 'you', 'have', 'typed', 'since', 'the', 'session', 'began', 'to', 'be', 'able', 'to', 'reuse', '.']\n",
      "['Generates', 'text', 'files', 'so', 'it', 'should', 'be', 'easy', 'to', 'fix', 'using', 'any', 'text', 'editor', ',', 'like', 'Kate', '.']\n",
      "['Ctrl', 'S', 'Save', 'Log']\n",
      "['Saves', 'the', 'log', 'with', 'all', 'results', 'into', 'an', 'HTML', 'file', 'to', 'be', 'able', 'to', 'print', 'or', 'publish', '.']\n",
      "['Ctrl', 'Q', 'Quit']\n",
      "['Shuts', 'the', 'program', 'down', '.']\n",
      "['To', 'add', 'a', 'new', '2D', 'graph', 'on', 'kalgebra', ',', 'what', 'you', 'have', 'to', 'do', 'is', 'to', 'go', 'to', 'the', '2D', 'Graph', 'tab', 'and', 'click', 'in', 'the', 'Add', 'tab', 'to', 'add', 'the', 'new', 'function', '.']\n",
      "['Then', 'your', 'focus', 'will', 'go', 'to', 'an', 'input', 'text', 'box', 'where', 'you', 'can', 'type', 'your', 'function', '.']\n",
      "['If', 'you', 'want', 'to', 'use', 'a', 'typical', 'f(x)', 'function', 'it', 'is', 'not', 'necessary', 'to', 'specify', 'it', '.']\n",
      "['If', 'you', 'have', 'entered', 'the', 'function', 'click', 'on', 'the', 'OK', 'button', 'to', 'display', 'the', 'graph', 'in', 'the', 'main', 'window', '.']\n",
      "['You', 'can', 'set', 'several', 'graphs', 'on', 'the', 'same', 'view', '.']\n",
      "['Just', 'use', 'the', 'Add', 'button', 'when', 'you', 'are', 'in', 'List', 'mode', '.']\n",
      "['You', 'can', 'set', 'each', 'graph', 'its', 'own', 'color', '.']\n",
      "['The', 'Foundation', 'has', 'recently', 'been', 'involved', 'in', 'organising', 'a', 'conference', 'which', 'dealt', 'with', 'this', 'critical', 'challenge', '.']\n",
      "['Over', '100', 'participants', 'from', 'the', 'main', 'interest', 'groups', 'attended', 'and', 'debated', 'issues', 'such', 'as', 'the', 'role', 'of', 'key', 'actors', 'including', 'public', 'authorities', ',', 'social', 'partners', ',', 'voluntary', 'and', 'community', 'organisations', 'as', 'well', 'as', 'service', 'users', '.']\n",
      "['Note', 'was', 'also', 'taken', 'of', 'the', 'variety', 'of', 'different', 'roles', 'played', 'by', 'public', 'welfare']\n",
      "['The', 'Foundation', 'organised', ',', 'together', 'with', 'the', 'European', 'Commission', ',', 'the', 'Spanish', 'Ministry', 'of', 'Social', 'Affairs', 'and', 'the', 'Galician', 'regional', 'government', ',', 'a', 'European', 'conference', 'on', 'social', 'exclusion', ':', 'a', 'major', 'challenge', 'for', 'public', 'welfare', 'services', '.']\n",
      "['The', 'Foundation', 'recently', 'published', 'a', 'comparative', 'study', 'as', 'part', 'of', 'the', 'EPOC', 'project', 'which', 'assesses', 'the', 'extent', 'to', 'which', 'direct', 'participation', 'can', 'humanise', 'work', 'while', 'increasing', 'profitability', '.']\n",
      "['The', 'study', 'is', 'based', 'on', '195', 'personal', 'interviews', 'with', 'senior', 'officials', 'of', 'the', 'social', 'partners', 'as', 'representatives', 'of', 'national', 'level', 'peak', 'organisations', 'in', 'fifteen', 'European', 'countries', '.']\n",
      "['As', 'important', 'industrial', 'sectors', ',', 'the', 'metal', 'industry', 'and', 'the', 'banking', 'sector', 'were', 'also', 'included', '.']\n",
      "['Key', 'speakers', 'at', 'the', 'social', 'exclusion', 'conference', 'were', '(', 'left', 'to', 'right', ')', 'Cristina', 'Louro', ',', 'Employment', ',', 'Industrial', 'Relations', 'and', 'Social', 'Affairs', 'Directorate', ',', 'European', 'Commission', 'Fernando', 'Gomes', ',', 'a', 'high', 'degree', 'of', 'Committee', 'of', 'the', 'Regions', 'Barbara', 'Weiler', ',', 'Member', 'of', 'the', 'European', 'Parliament', 'José', 'Maria', 'Gil-Robles', ',', 'Vice-President', ',', 'European', 'Parliament', 'and', 'John', 'Carroll', ',', 'Economic', 'and', 'Social', 'Committee', '.']\n",
      "['Case', 'Studies', 'Each', 'national', 'report', 'contains', 'a', 'portfolio', 'of', 'between', '25', 'and', '30', 'initiatives', 'which', 'best', 'present', 'policies', 'and', 'practices', 'to', 'improve', 'the', 'recruitment', ',', 'training', 'and', 'development', 'of', 'ageing', 'workers', 'in', 'both', 'the', 'work', 'place', 'and', 'the', 'community', '.']\n",
      "['For', 'each', 'country', ',', 'two', 'or', 'three', 'initiatives', 'have', 'been', 'selected', 'for', 'further', 'in', 'depth', 'case', 'study', '.']\n",
      "['These', 'case', 'studies', 'analysed', 'the', 'background', 'of', 'the', 'initiatives', ',', 'their', 'impact', 'on', 'employment', 'patterns', 'and', 'work', 'organisations', 'and', 'assessed', 'the', 'benefits', 'and', 'problems', 'of', 'the', 'initiative', '.']\n",
      "['Visits', 'and', 'interviews', 'with', 'key', 'personnel', 'were', 'also', 'undertaken', '.']\n",
      "['These', 'national', 'studies', 'will', 'form', 'the', 'basis', 'of', 'a', 'European', 'report', 'which', 'synthesises', 'overall', 'practices', '.']\n",
      "['The', 'report', 'and', 'a', 'case', 'book', 'of', 'initiatives', 'will', 'be', 'published', 'in', '1996', 'and', 'provide', 'the', 'backdrop', 'for', 'a', 'conference', 'to', 'be', 'staged', 'in', 'Autumn', ',', '1996', '.']\n",
      "['The', 'Foundation', 'aims', 'to', 'document', 'the', 'characteristics', 'of', 'age', 'barriers', 'in', 'job', 'recruitment', 'and', 'training', 'and', 'to', 'analyse', 'their', 'causes', '.']\n",
      "['The', 'perspectives', 'of', 'the', 'social', 'partners', 'is', 'also', 'being', 'examined', ',', 'with', 'particular', 'attention', 'paid', 'to', 'proposals', 'for', 'removing', 'age', 'barriers', '.']\n",
      "['Thirdly', ',', 'the', 'project', 'documents', 'and', 'assesses', 'initiatives', ',', 'in', 'both', 'the', 'public', 'and', 'private', 'sectors', 'which', 'combat', 'age', 'barriers', ',', 'especially', 'for', 'older', 'workers', '.']\n",
      "['Seeking', 'alternatives', 'to', 'early', 'retirement', 'and', 'redundancy', ',', 'the', 'project', 'is', 'primarily', 'concerned', 'with', 'the', 'retention', ',', 'reintegration', 'and', 'retraining', 'of', 'older', 'workers', '.']\n",
      "['The', 'gender', 'and', 'ethnic', 'backgrounds', 'of', 'workers', 'and', 'how', 'these', 'relate', 'to', 'age', 'discrimination', 'are', 'examined', '.']\n",
      "['The', 'project', 'also', 'considers', 'initiatives', 'to', 'combat', 'age', 'discrimination', 'in', 'rural', 'areas', 'and', 'in', 'small', 'and', 'medium', 'sized', 'enterprises', '.']\n",
      "['Seven', 'member', 'states', 'are', 'covered', 'by', 'the', 'project', ':', 'Belgium', ',', 'France', ',', 'Germany', ',', 'Greece', ',', 'Italy', ',', 'the', 'Netherlands', 'and', 'the', 'United', 'Kingdom', '.']\n",
      "['What', 'is', 'Cerenia', '?']\n",
      "['Cerenia', 'contains', 'the', 'active', 'substance', 'maropitant', 'and', 'is', 'available', 'as', 'tablet', 'or', 'as', 'solution', 'for', 'injection', '.']\n",
      "['The', 'tablets', 'are', 'pale-orange', 'and', 'have', 'a', 'score', 'line', 'on', 'both', 'sides', 'so', 'that', 'they', 'can', 'be', 'halved', '.']\n",
      "['Each', 'tablet', 'is', 'marked', 'with', 'the', 'Pfizer', 'logo', 'on', 'one', 'side', 'and', 'with', 'the', 'letters', 'MPT', 'and', 'the', 'quantity', 'of', 'maropitant', 'on', 'the', 'other', 'side', '.']\n",
      "['What', 'is', 'Cerenia', 'used', 'for', '?']\n",
      "['Cerenia', 'is', 'an', 'anti-emetic', ',', 'this', 'means', 'that', 'it', 'stops', 'vomiting', '.']\n",
      "['It', 'is', 'used', 'in', 'dogs', 'to', 'prevent', 'vomiting', 'such', 'as', 'vomiting', 'caused', 'by', 'chemotherapy', '(', 'medicines', 'used', 'for', 'the', 'treatment', 'of', 'cancer', ',', 'some', 'of', 'which', 'are', 'known', 'to', 'cause', 'vomiting', ')', '.']\n",
      "['In', 'combination', 'with', 'supportive', 'measures', 'such', 'as', 'other', 'veterinary', 'treatment', 'or', 'a', 'special', 'diet', ',', 'Cerenia', 'can', 'also', 'be', 'used', 'in', 'the', 'treatment', 'of', 'vomiting', '(', 'either', 'as', 'injection', 'or', 'as', 'injection', 'followed', 'by', 'tablets', ')', '.']\n",
      "['For', 'these', 'purposes', ',', 'Cerenia', 'can', 'be', 'given', 'for', 'up to', 'five', 'days']\n",
      "['How', 'does', 'Cerenia', 'work', '?']\n",
      "['Cerenia', 'blocks', 'a', 'neurokinin', '1', '(', 'NK1', ')', 'receptor', ',', 'which', 'acts', 'in', 'the', 'central', 'nervous', 'system', '.']\n",
      "['How', 'has', 'Cerenia', 'been', 'studied', '?']\n",
      "['A', 'large', 'number', 'of', 'studies', 'with', 'Cerenia', 'were', 'carried', 'out', 'either', 'in', 'laboratory', 'dogs', 'or', 'in', 'animal', 'patients', 'at', 'veterinary', 'practises', 'in', 'several', 'European', 'countries', 'and', 'in', 'the', 'USA', '.']\n",
      "['What', 'benefit', 'has', 'Cerenia', 'shown', 'during', 'the', 'studies', '?']\n",
      "['The', 'results', 'of', 'the', 'studies', 'showed', 'that', 'Cerenia', 'was', 'more', 'effective', 'than', 'the', 'placebo', ':', 'less', 'vomiting', 'was', 'seen', 'in', 'dogs', 'that', 'received', 'the', 'medicine', 'than', 'in', 'dogs', 'that', 'received', 'a', 'placebo', ',', 'both', 'in', 'the', 'treatment', 'or', 'in', 'the', 'prevention', 'of', 'vomiting', '.']\n",
      "['The', 'treatment', 'of', 'a', 'vomiting', 'dog', 'should', 'be', 'started', 'with', 'the', 'injection', ',', 'since', 'vomiting', 'animals', 'might', 'not', 'be', 'able', 'to', 'keep', 'a', 'tablet', 'down', '(', 'as', 'they', 'might', 'throw', 'the', 'intact', 'tablet', 'up', 'again', ')', '.']\n",
      "['For', 'follow-up', 'treatment', ',', 'the', 'animal', 'owner', 'can', 'administer', 'the', 'tablets', 'to', 'the', 'dog', '.']\n",
      "['Also', ',', 'the', 'treatment', 'of', 'vomiting', 'should', 'only', 'be', 'together', 'with', 'other', 'supportive', 'measure', 'or', 'other', 'veterinary', 'therapy', 'while', 'addressing', 'the', 'underlying', 'causes', 'of', 'the', 'vomiting', '.']\n",
      "['What', 'is', 'the', 'risk', 'associated', 'with', 'Cerenia', '?']\n",
      "['Cerenia', 'was', 'generally', 'well', 'tolerated', 'when', 'administered', 'daily', 'at', 'dosages', 'up', 'to', '5', 'times', 'the', 'recommended', 'doses', 'for', 'an', 'extended', 'period', 'of', 'time', '(', 'up', 'to', '3', 'times', 'the', 'recommended', 'maximum', 'duration', 'of', 'treatment', ')', '.']\n",
      "['What', 'are', 'the', 'precautions', 'for', 'the', 'person', 'who', 'gives', 'the', 'medicine', 'or', 'comes', 'into', 'contact', 'with', 'the', 'animal', '?']\n",
      "131 138\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idxes = raw_sense_df['Token ID'].tolist()\n",
    "tokens = raw_sense_df['Token'].tolist()\n",
    "en_sents = []\n",
    "pre_sid = None\n",
    "s = []\n",
    "for i, t in zip(idxes, tokens):\n",
    "    # print(i)\n",
    "    sid = i.split('.')[1]\n",
    "    if sid != pre_sid:\n",
    "        if s:\n",
    "            en_sents.append(s)\n",
    "        pre_sid = sid\n",
    "        s = [t]\n",
    "    else:\n",
    "        s.append(t)\n",
    "en_sents.append(s)\n",
    "\n",
    "\n",
    "idxes = tkns_df['Token ID'].tolist()\n",
    "tokens = tkns_df['Token'].tolist()\n",
    "\n",
    "tgt_sents = []\n",
    "pre_sid = None\n",
    "s = []\n",
    "for i, t in zip(idxes, tokens):\n",
    "    sid = i.split('.')[1]\n",
    "    if sid != pre_sid:\n",
    "        if s:\n",
    "            tgt_sents.append(s)\n",
    "        pre_sid = sid\n",
    "        s = [t]\n",
    "    else:\n",
    "        s.append(t)\n",
    "tgt_sents.append(s)\n",
    "\n",
    "print(len(en_sents),len(tgt_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c859b938",
   "metadata": {},
   "source": [
    "Run the below cell only if you are using the files in the English/second-sense directory as well as the provided Spanish or Italian files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a35f146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "[['En', 'el', 'presente', 'documento', 'se', 'resume', 'el', 'Informe', 'Público', 'Europeo', 'de', 'Evaluación', '(', 'EPAR', ')', '.'], ['En', 'él', 'se', 'explica', 'cómo', 'el', 'Comité', 'de', 'Medicamentos', 'de', 'Uso', 'Humano', '(', 'CHMP', ')', 'ha', 'evaluado', 'los', 'estudios', 'realizados', 'con', 'el', 'medicamento', 'a fin de', 'emitir', 'unas', 'recomendaciones', 'sobre', 'su', 'uso', '.'], ['Si', 'desea', 'más', 'información', 'sobre', 'su', 'enfermedad', 'o', 'el', 'tratamiento', 'de', 'la', 'misma', ',', 'le', 'aconsejamos', 'que', 'lea', 'el', 'prospecto', '(', 'incluido', 'en', 'el', 'EPAR', ')', 'o', 'pregunte', 'a', 'su', 'médico', 'o', 'su', 'farmacéutico', '.'], ['Si', 'desea', 'más', 'información', 'sobre', 'el', 'fundamento', 'en', 'el', 'que', 'se', 'han', 'basado', 'las', 'recomendaciones', 'del', 'CHMP', ',', 'le', 'aconsejamos', 'que', 'lea', 'el', 'Debate', 'Científico', '(', 'también', 'incluido', 'en', 'el', 'EPAR', ')', '.'], ['¿Qué', 'es', 'Alimta', '?'], ['Alimta', 'es', 'un', 'polvo', 'con', 'el', 'que', 'se', 'prepara', 'una', 'solución', 'para', 'perfusión', '(', 'goteo', 'en', 'vena', ')', '.'], ['Contiene', 'el', 'principio', 'activo', 'pemetrexed', '.'], ['¿Para', 'qué', 'se', 'utiliza', 'Alimta', '?'], ['Alimta', 'está', 'indicado', 'para', 'el', 'tratamiento', 'de', 'dos', 'tipos', 'de', 'cáncer', ':', 'mesotelioma', 'pleural', '(', 'cáncer', 'del', 'revestimiento', 'de', 'los', 'pulmones', 'causado', 'generalmente', 'por', 'la', 'exposición', 'al', 'amianto', ')', '.'], ['Alimta', 'se', 'administra', 'en', 'combinación', 'con', 'cisplatino', '(', 'otro', 'medicamento', 'contra', 'el', 'cáncer', ')', 'cuando', 'el', 'tumor', '«', 'no', 'es', 'resecable', '»', '(', 'no', 'puede', 'extirparse', 'sólo', 'mediante', 'cirugía', ')', 'y', 'es', '«', 'maligno', '»', '(', 'se', 'ha', 'extendido', ',', 'o', 'es', 'probable', 'que', 'se', 'extienda', 'fácilmente', ',', 'a', 'otras', 'partes', 'del', 'cuerpo', ')', ',', 'en', 'pacientes', 'que', 'no', 'han', 'recibido', 'quimioterapia', '(', 'medicamentos', 'contra', 'el', 'cáncer', ')', 'previamente', ',', 'cáncer', 'de', 'pulmón', '«', 'no', 'microcítico', '»', 'avanzado', 'o', 'metastásico', 'que', 'no', 'afecte', 'a', 'las', 'células', '«', 'escamosas', '»', '.'], ['Alimta', 'se', 'utiliza', 'en', 'combinación', 'con', 'cisplatino', 'en', 'pacientes', 'que', 'no', 'han', 'sido', 'tratados', 'previamente', 'y', 'en', 'monoterapia', 'en', 'pacientes', 'que', 'han', 'sido', 'tratado', 'previamente', 'con', 'otros', 'tipos', 'de', 'quimioterapia', '.'], ['Este', 'medicamento', 'sólo', 'podrá', 'dispensarse', 'con', 'receta', 'médica', '.'], ['¿Cómo', 'se', 'usa', 'Alimta', '?'], ['Alimta', 'sólo', 'debe', 'administrarse', 'bajo', 'la', 'supervisión', 'de', 'un', 'médico', 'cualificado', 'en', 'el', 'uso', 'de', 'quimioterapia', 'contra', 'el', 'cáncer', '.'], ['La', 'dosis', 'recomendada', 'de', 'Alimta', 'es', 'de', '500', 'mg', 'por', 'metro', 'cuadrado', 'de', 'superficie', 'corporal', '(', 'calculada', 'a partir de', 'la', 'estatura', 'y', 'el', 'peso', 'del', 'paciente', ')', '.', 'Se', 'administra', 'una', 'vez', 'cada', 'tres', 'semanas', 'por', 'perfusión', 'intravenosa', 'durante', '10', 'minutos', '.'], ['Con', 'el', 'fin', 'de', 'reducir', 'los', 'efectos', 'secundarios', ',', 'los', 'pacientes', 'deben', 'recibir', 'un', 'corticosteroide', 'y', 'ácido', 'fólico', '(', 'un', 'tipo', 'de', 'vitamina', ')', ',', 'así como', 'inyecciones', 'de', 'vitamina', 'B12', 'durante', 'el', 'tratamiento', 'con', 'Alimta', '.'], ['Cuando', 'Alimta', 'se', 'utiliza', 'conjuntamente', 'con', 'cisplatino', ',', 'hay que', 'administrar', 'además', 'un', 'medicamento', '«', 'antiemético', '»', '(', 'para', 'evitar', 'los', 'vómitos', ')', 'y', 'líquidos', '(', 'para', 'evitar', 'la', 'deshidratación', ')', 'antes', 'o', 'después de', 'la', 'dosis', 'de', 'cisplatino', '.'], ['Será', 'necesario', 'retrasar', 'o', 'suspender', 'el', 'tratamiento', ',', 'o', 'reducir', 'la', 'dosis', ',', 'en', 'pacientes', 'que', 'presenten', 'alteraciones', 'en', 'los', 'recuentos', 'sanguíneos', 'o', 'determinados', 'efectos', 'secundarios', '.'], ['No', 'se', 'recomienda', 'administrar', 'Alimta', 'a', 'pacientes', 'con', 'problemas', 'renales', 'moderados', 'o', 'graves', '.'], ['Si', 'desea', 'más', 'información', ',', 'consulte', 'el', 'Resumen', 'de', 'las', 'Características', 'del', 'Producto', ',', 'que', 'también', 'forma', 'parte', 'del', 'EPAR', '.'], ['¿Cómo', 'actúa', 'Alimta', '?'], ['El', 'principio', 'activo', 'de', 'Alimta', ',', 'el', 'pemetrexed', ',', 'es', 'un', 'medicamento', 'citotóxico', '(', 'un', 'medicamento', 'que', 'destruye', 'las', 'células', 'que', 'están', 'en', 'fase', 'de', 'división', ',', 'como', 'las', 'cancerosas', ')', 'que', 'pertenece', 'al', 'grupo', 'de', 'los', '«', 'antimetabolitos', '»', '.'], ['En', 'el', 'organismo', ',', 'el', 'pemetrexed', 'se', 'convierte', 'en', 'una', 'forma', 'activa', 'que', 'bloquea', 'la', 'actividad', 'de', 'las', 'enzimas', 'que', 'participan', 'en', 'la', 'producción', 'de', '«', 'nucleótidos', '»', '(', 'elementos', 'esenciales', 'del', 'ADN', 'y', 'el', 'ARN', ',', 'el', 'material', 'genético', 'de', 'las', 'células', ')', '.'], ['¿Qué', 'tipo', 'de', 'estudios', 'se', 'han', 'realizado', 'con', 'Alimta', '?'], ['Por', 'lo', 'que', 'se', 'refiere', 'al', 'tratamiento', 'del', 'mesotelioma', 'pleural', 'maligno', ',', 'Alimta', 'ha', 'sido', 'evaluado', 'en', 'un', 'estudio', 'principal', 'realizado', 'en', '456', 'pacientes', 'que', 'no', 'habían', 'recibido', 'quimioterapia', 'anteriormente', '.'], ['Se', 'compararon', 'los', 'efectos', 'de', 'Alimta', 'en', 'combinación', 'con', 'cisplatino', 'con', 'los', 'efectos', 'del', 'cisplatino', 'administrado', 'en', 'solitario', '.'], ['En', 'cuanto', 'al', 'tratamiento', 'del', 'cáncer', 'de', 'pulmón', 'no', 'microcítico', ',', 'se', 'compararon', 'los', 'efectos', 'de', 'Alimta', 'con', 'los', 'del', 'docetaxel', '(', 'otro', 'medicamento', 'contra', 'el', 'cáncer', ')', 'en', 'un', 'estudio', 'realizado', 'en', '571', 'pacientes', 'con', 'enfermedad', 'localmente', 'avanzada', 'o', 'metastásica', 'que', 'habían', 'recibido', 'quimioterapia', 'previamente', '.'], ['Alimta', 'también', 'se', 'comparó', 'con', 'gemcitabina', '(', 'otro', 'medicamento', 'contra', 'el', 'cáncer', ')', ',', 'ambos', 'en', 'combinación', 'con', 'cisplatino', ',', 'en', 'un', 'estudio', 'con', '1.725', 'pacientes', 'que', 'no', 'habían', 'recibido', 'quimioterapia', 'contra', 'el', 'cáncer', 'de', 'pulmón', 'previamente', '.'], ['En', 'los', 'tres', 'estudios', ',', 'el', 'criterio', 'principal', 'de', 'valoración', 'de', 'la', 'eficacia', 'fue', 'el', 'tiempo', 'de', 'supervivencia', 'de', 'los', 'pacientes', '.'], ['¿Qué', 'beneficio', 'ha', 'demostrado', 'tener', 'Alimta', 'durante', 'los', 'estudios', '?'], ['Alimta', 'prolongó', 'el', 'tiempo', 'de', 'supervivencia', 'de', 'los', 'pacientes', 'con', 'mesotelioma', 'pleural', 'maligno', '.'], ['Los', 'pacientes', 'que', 'recibieron', 'Alimta', 'y', 'cisplatino', 'sobrevivieron', 'una', 'media', 'de', '12,1', 'meses', ',', 'mientras que', 'la', 'supervivencia', 'de', 'los', 'enfermos', 'tratados', 'sólo', 'con', 'cisplatino', 'fue', 'de', '9,3', 'meses', '.'], ['En', 'el', 'tratamiento', 'de', 'pacientes', 'con', 'cáncer', 'de', 'pulmón', 'no', 'microcítico', ',', 'Alimta', 'fue', 'tan', 'efectivo', 'como', 'los', 'medicamentos', 'de', 'comparación', '.'], ['En', 'los', 'pacientes', 'que', 'habían', 'recibido', 'quimioterapia', 'previamente', ',', 'el', 'tiempo', 'medio', 'de', 'supervivencia', 'fue', 'de', '8,3', 'meses', 'con', 'Alimta', 'frente a', '7,9', 'meses', 'con', 'docetaxel', '.'], ['En', 'pacientes', 'que', 'no', 'habían', 'recibido', 'previamente', 'quimioterapia', ',', 'el', 'tiempo', 'medio', 'de', 'supervivencia', 'fue', 'de', '10,3', 'meses', 'en', 'ambos', 'grupos', '.'], ['No obstante', ',', 'los', 'pacientes', 'de', 'ambos', 'estudios', 'cuyo', 'cáncer', 'no', 'afectaba', 'a', 'las', 'células', 'escamosas', 'presentaban', 'un', 'mayor', 'tiempo', 'de', 'supervivencia', 'cuando', 'recibían', 'Alimta', 'que', 'cuando', 'recibían', 'el', 'medicamento', 'de', 'comparación', '.'], ['Por el contrario', ',', 'los', 'pacientes', 'cuyo', 'cáncer', 'estaba', 'afectando', 'a', 'las', 'células', 'escamosas', 'presentaron', 'tiempos', 'de', 'supervivencia', 'más', 'breve', 'si', 'se', 'les', 'trataba', 'con', 'Alimta', '.', 'kalgebra', 'es', 'una', 'calculadora', 'matemática', 'basada', 'en', 'el', 'lenguaje', 'de', 'marcado', 'MathML', '.'], ['Hoy', 'en', 'día', 'es', 'capaz', 'de', 'realizar', 'operaciones', 'simples', '(', 'aritméticas', 'y', 'lógicas', ')', 'usando', 'MathML', 'y', 'de', 'representarlas', 'en', 'gráficas', 'de', 'dos', 'y', 'tres', 'dimensiones', '.'], ['No', 'es', 'necesario', 'conocer', 'MathML', 'para', 'usar', 'kalgebra', '.', 'kalgebra', 'es', 'una', 'calculadora', 'gráfica', 'basada', 'en', 'MathML', '.'], ['Aunque', 'en', 'un', 'principio', 'estuvo', 'orientado', 'a', 'MathML', ',', 'actualmente', 'puede', 'ser', 'usado', 'por', 'cualquier', 'persona', ',', 'aunque', 'posea', 'pocos', 'conocimientos', 'matemáticos', '.'], ['Aquí', 'se', 'muestra', 'una', 'captura', 'de', 'la', 'ventana', 'principal', 'de', 'kalgebra', '.', 'Ventana', 'principal', 'de', 'kalgebra', 'La', 'ventana', 'principal', 'de', 'kalgebra', 'consta', 'de', 'cuatro', 'pestañas', ':', 'Consola', ',', 'Gráfica', '2D', ',', 'Gráfica', '3D', 'y', 'Diccionario', '.'], ['Bajo', 'estas', 'pestañas', 'encontrará', 'un', 'campo', 'de', 'entrada', 'donde', 'podrá', 'introducir', 'sus', 'funciones', 'o', 'realizar', 'sus', 'cálculos', '.'], ['Para', 'entender', 'cómo', 'funciona', ',', 'conviene', 'comprender', 'que', 'lo', 'que', 'introducimos', 'está', 'siendo', 'convertido', 'a', 'MathML', ',', 'aunque', 'no', 'es', 'necesario', 'conocer', 'MathML', '.'], ['He', 'basado', 'la', 'sintaxis', 'en', 'el', 'sentido', 'común', ',', 'por', 'lo', 'que', 'debería', 'ser', 'asequible', 'para', 'todos', '.'], ['He', 'tenido', 'también', 'en', 'cuenta', 'las', 'sintaxis', 'de', 'Maxima', 'y', 'Maple', ',', 'por', 'lo', 'que', 'es', 'muy', 'similar', 'a', 'estas', '.', '+', '-', '*', '/', ':', 'suma', ',', 'resta', ',', 'multiplicación', 'y', 'división', '.', '^', ',', '**', ':', 'potencia', ',', 'puede', 'usar', 'cualquiera', 'de', 'las', 'dos', 'formas', '.'], ['Asimismo', ',', 'puede', 'usar', 'los', 'caracteres', 'unicode', '²', '.'], ['Las', 'potencias', 'son', 'también', 'una', 'forma', 'de', 'expresar', 'raíces', '.', '-gt', ':', 'Permite', 'especificar', 'la', 'variable', 'limitada', 'en', 'una', 'función', '.', '(', ')', ':', 'se', 'usa', 'para', 'especificar', 'una', 'prioridad', 'mayor', '.', 'abc(parámetros)', ':', 'Cuando', 'el', 'analizador', 'sintáctico', 'encuentra', 'una', 'función', ',', 'comprueba', 'si', '«', 'abc', '»', 'es', 'un', 'operador', '.'], ['Si', 'lo', 'es', ',', 'lo', 'trata', 'como', 'un', 'operador', 'si', 'no', 'lo', 'es', ',', 'lo', 'trata', 'como', 'una', 'función', 'de', 'usuario', '.', ':', '=', ':', 'Se', 'usa', 'para', 'definir', 'el', 'valor', 'de', 'una', 'variable', '.', '?', ':', 'definición', 'de', 'condiciones', 'en', 'funciones', 'definidas', 'a', 'trozos', '(', '«', 'piecewise', '»', ')', '.'], ['Permite', 'definir', 'operaciones', 'condicionales', 'en', 'kalgebra', '.'], ['Cuando', 'introducimos', 'la', 'condición', 'antes', 'del', 'símbolo', '«', '?', '»', ',', 'kalgebra', 'utiliza', 'esta', 'condición', 'solo', 'si', 'es', 'verdadera', 'en cambio', ',', 'si', 'encuentra', 'un', 'símbolo', '«', '?', '»', 'sin', 'ninguna', 'condición', ',', 'toma', 'en', 'cuenta', 'el', 'último', 'caso', '.', '{', '}', ':', 'Puede', 'usarse', 'para', 'definir', 'un', 'contenedor', '.'], ['Es', 'muy', 'útil', 'a', 'la', 'hora', 'de', 'trabajar', 'con', 'funciones', 'definidas', 'a', 'trozos', '.'], ['Ahora', 'puede', 'preguntarme', 'por qué', 'debería', 'el', 'usuario', 'preocuparse', 'por', 'MathML', '.', 'La', 'respuesta', 'es', 'fácil', '.', 'Con', 'esto', 'podremos', 'realizar', 'operaciones', 'con', 'funciones', 'como', 'cos()', ',', 'sin()', '(', 'o', 'cualquier', 'otra', 'función', 'trigonométrica', ')', ',', 'sum()', 'o', 'product()', '.'], ['No', 'importa', 'el', 'tipo', 'de', 'función', 'que', 'sea', '.'], ['Podremos', 'usar', 'plus()', ',', 'times()', 'y', 'cualquier', 'cosa', 'a la que', 'le', 'corresponda', 'un', 'operador', '.', 'La', 'consola', 'de', 'kalgebra', 'es', 'tan', 'útil', 'como', 'una', 'calculadora', '.'], ['Aquí', 'tiene', 'una', 'lista', 'de', 'las', 'variables', 'declaradas', '.'], ['Si', 'pulsa', 'dos', 'veces', 'sobre', 'una', 'de', 'ellas', ',', 'le', 'aparecerá', 'un', 'diálogo', 'con', 'el', 'que', 'podrá', 'cambiar', 'su', 'valor', '(', 'es', 'una', 'forma', 'de', 'engañar', 'al', 'registro', ')', '.'], ['Cada vez que', 'introduzca', 'una', 'expresión', ',', 'el', 'valor', 'de', 'la', 'variable', '«', 'ans', '»', 'cambiará', 'para', 'reproducir', 'el', 'último', 'resultado', '.'], ['Ctrl', 'N', 'Nuevo'], ['Refresca', 'el', 'registro', '.'], ['Ctrl', 'L', 'Cargar', 'un', 'guión'], ['Ejecuta', 'las', 'instrucciones', 'en', 'una', 'archivo', 'de', 'forma', 'secuencial', '.'], ['Es', 'útil', 'si', 'lo', 'que', 'desea', 'es', 'definir', 'una', 'biblioteca', 'o', 'reanudar', 'un', 'trabajo', 'anterior', '.'], ['Ctrl', 'G', 'Guardar', 'el', 'guión'], ['Guarda', 'las', 'intrucciones', 'que', 'ha', 'introducido', 'desde', 'que', 'comenzó', 'la', 'sesión', ',', 'con', 'lo', 'que', 'podrá', 'reutilizarlas', '.'], ['Genera', 'un', 'archivo', 'de', 'texto', 'que', 'podrá', 'corregir', 'usando', 'cualquier', 'editor', 'de', 'texto', ',', 'por ejemplo', 'Kate', '.'], ['Ctrl', 'S', 'Guardar', 'el', 'registro'], ['Guarda', 'el', 'registro', 'con', 'todos', 'los', 'resultados', 'en', 'un', 'archivo', 'HTML', 'que', 'podrá', 'imprimir', 'o', 'publicar', '.'], ['Ctrl', 'Q', 'Salir'], ['Cierra', 'el', 'programa', '.'], ['Para', 'añadir', 'un', 'gráfica', '2D', 'en', 'kalgebra', ',', 'lo', 'que', 'tiene que', 'hacer', 'es', 'ir', 'a', 'la', 'pestaña', 'Gráfica', '2D', 'y', 'aquí', 'pulsar', 'la', 'pestaña', 'Añadir', ',', 'que', 'le', 'permitirá', 'añadir', 'una', 'nueva', 'función', '.'], ['A', 'continuación', 'tendrá', 'dirigirse', 'al', 'cuadro', 'de', 'texto', 'de', 'entrada', ',', 'donde', 'podrá', 'introducir', 'su', 'función', '.'], ['Si', 'quiere', 'usar', 'una', 'función', 'f(x)', 'típica', ',', 'no', 'es', 'necesario', 'que', 'la', 'especifique', '.'], ['Después de', 'haber', 'introducido', 'la', 'función', ',', 'pulse', 'el', 'botón', 'Aceptar', 'para', 'dibujar', 'la', 'gráfica', 'en', 'la', 'ventana', 'principal', '.'], ['Es', 'posible', 'dibujar', 'varias', 'gráficas', 'en', 'la', 'misma', 'vista', '.'], ['Para', 'esto', 'use', 'simplemente', 'el', 'botón', 'Añadir', 'cuando', 'se', 'encuentre', 'en', 'el', 'modo', 'Lista', '.'], ['Puede', 'ajustar', 'el', 'color', 'de', 'cada', 'gráfica', '.'], ['La', 'Fundación', 'ha', 'intervenido', 'recientemente', 'en', 'la', 'organización', 'de', 'una', 'conferencia', 'sobre', 'este', 'decisivo', 'reto', '.'], ['Asistieron', 'más', 'de', '100', 'participantes', 'en', 'representación', 'de', 'los', 'principales', 'grupos', 'de', 'interés', ',', 'los', 'cuales', 'discutieron', 'cuestiones', 'tales', 'como', 'el', 'papel', 'de', 'los', 'principales', 'agentes', ',', 'entre', 'ellos', ',', 'las', 'autoridades', 'públicas', ',', 'los', 'interlocutores', 'sociales', 'y', 'las', 'organizaciones', 'comunitarias', 'y', 'de', 'voluntarios', ',', 'además', 'de', 'los', 'propios', 'usuarios', '.'], ['Se', 'llegó', 'a', 'la', 'conclusión', 'de', 'que', 'es', 'necesario', 'adoptar', 'un', 'enfoque', 'más', 'global', 'que', 'tenga en cuenta', 'que', 'los', 'usuarios', 'no', 'se', 'sirven', 'de', 'esos', 'servicios', 'de', 'forma', 'aislada', ',', 'sino', 'como', 'parte', 'de', 'su', 'vida', 'cotidiana', '.'], ['Se', 'tomó', 'nota', 'también', 'de', 'la', 'diversidad', 'de', 'funciones', 'que', 'desempeñan', 'estos', 'servicios'], ['La', 'Fundación', 'organizó', ',', 'junto con', 'la', 'Comisión', 'Europea', ',', 'el', 'Ministerio', 'español', 'de', 'Asuntos', 'Sociales', 'y', 'la', 'Comunidad', 'Autónoma', 'de', 'Galicia', ',', 'una', 'conferencia', 'europea', 'sobre', 'el', 'tema', '\"\"\"\"', 'Exclusión', 'social', ':', 'Un', 'gran', 'reto', 'para', 'los', 'servicios', 'públicos', 'de', 'protección', 'social', '\"\"\"\"', '.'], ['La', 'Fundación', 'publicó', 'recientemente', 'en', 'el', 'marco', 'del', 'proyecto', 'EPOC', 'un', 'estudio', 'comparativo', 'en', 'el', 'que', 'se', 'evalúa', 'hasta', 'qué', 'punto', 'la', 'participación', 'directa', 'puede', 'humanizar', 'el', 'trabajo', 'e', 'incrementar', 'al mismo tiempo', 'la', 'rentabilidad', '.'], ['El', 'estudio', 'se', 'basa', 'en', '195', 'entrevistas', 'personales', 'con', 'altos', 'responsables', 'de', 'los', 'interlocutores', 'sociales', ',', 'en', 'su', 'calidad', 'de', 'representantes', 'de', 'importantes', 'organizaciones', 'nacionales', 'de', '15', 'países', 'europeos', '.'], ['La', 'industria', 'del', 'metal', 'y', 'el', 'sector', 'bancario', 'se', 'incluyeron', 'también', 'en', 'atención', 'a', 'su', 'importancia', '.'], ['Los', 'principales', 'oradores', 'en', 'la', 'conferencia', 'sobre', 'exclusión', 'socialfueron', '(', 'de', 'izquierda', 'a', 'derecha', ')', 'Cristina', 'Louro', ',', 'Dirección', 'General', 'de', 'Empleo', ',', 'Relaciones', 'Laborales', 'y', 'Asuntos', 'Sociales', 'de', 'la', 'Comisión', 'Europea', 'Fernando', 'Gomes', ',', 'Comité', 'de', 'las', 'Regiones', 'Barbara', 'Weiler', ',', 'diputada', 'al', 'Parlamento', 'Europeo', 'José', 'María', 'Gil-Robles', 'Gil-Delgado', ',', 'Vicepresidente', ',', 'Parlamento', 'Europeo', ',', 'John', 'Carroll', 'Comité', 'Económico', 'y', 'Social'], ['En', 'cada', 'informe', 'nacional', 'se', 'incluyen', 'las', '25', 'o', '30', 'iniciativas', 'que', 'mejor', 'reflejan', 'prácticas', 'y', 'políticas', 'de', 'mejora', 'de', 'la', 'contratación', ',', 'la', 'formación', 'y', 'el', 'desarrollo', 'profesional', 'de', 'los', 'trabajadores', 'mayores', 'en', 'el', 'lugar', 'de', 'trabajo', 'y', 'a nivel de', 'la', 'comunidad', '.'], ['Se', 'seleccionaron', 'dos', 'o', 'tres', 'iniciativas', 'por', 'cada', 'país', ',', 'para', 'que', 'fueran', 'objeto', 'de', 'un', 'estudio', 'de', 'caso', 'detallado', '.'], ['En', 'estos', 'estudios', 'de', 'caso', 'se', 'han', 'analizado', 'el', 'contexto', 'de', 'esas', 'iniciativas', 'y', 'sus', 'repercusiones', 'en', 'las', 'pautas', 'de', 'empleo', 'y', 'en', 'las', 'organizaciones', ',', 'y', 'se', 'han', 'evaluado', 'las', 'ventajas', 'y', 'problemas', 'derivados', 'de', 'las', 'mismas', '.'], ['Se', 'han', 'realizado', 'además', 'visitas', 'y', 'entrevistas', 'a', 'miembros', 'clave', 'del', 'personal', '.'], ['Estos', 'estudios', 'nacionales', 'constituirán', 'la', 'liase', 'de', 'un', 'informe', 'europeo', 'en', 'el', 'que', 'se', 'resumirán', 'las', 'prácticas', 'generales', '.'], ['El', 'informe', 'y', 'un', 'repertorio', 'de', 'iniciativas', 'se', 'publicarán', 'en', '1996', ',', 'y', 'servirán', 'de', 'telón', 'de', 'fondo', 'a', 'una', 'conferencia', 'que', 'se', 'celebrará', 'el', 'próximo', 'otoño', '.'], ['La', 'Fundación', 'se', 'propone', 'documentar', 'las', 'características', 'de', 'los', 'obstáculos', 'relacionados', 'con', 'la', 'edad', 'en', 'materia', 'de', 'contratación', 'y', 'formación', ',', 'y', 'analizar', 'sus', 'causas', '.'], ['Está', 'examinando', 'asimismo', 'los', 'puntos', 'de', 'vista', 'de', 'los', 'interlocutores', 'sociales', ',', 'prestando', 'especial', 'atención', 'a', 'las', 'propuestas', 'para', 'eliminar', 'dichos', 'obstáculos', '.'], ['En', 'tercer', 'lugar', ',', 'el', 'proyecto', 'documenta', 'y', 'evalúa', 'las', 'iniciativas', 'de', 'los', 'sectores', 'público', 'y', 'privado', 'para', 'combatir', 'estas', 'limitaciones', ',', 'especialmente', 'en relación con', 'los', 'trabajadores', 'mayores', '.'], ['El', 'proyecto', ',', 'que', 'busca', 'alternativas', 'a', 'la', 'jubilación', 'anticipada', 'y', 'al', 'despido', ',', 'se', 'ocupa', 'ante', 'todo', 'de', 'la', 'retención', ',', 'la', 'reintegración', 'y', 'la', 'reconversión', 'profesional', 'de', 'los', 'trabajadores', 'mayores', '.'], ['Estudia', 'asimismo', 'liasta', 'qué', 'punto', 'influyen', 'el', 'sexo', 'y', 'la', 'raza', 'de', 'los', 'trabajadores', 'en', 'la', 'discriminación', 'por', 'razón', 'de', 'la', 'edad', '.'], ['El', 'proyecto', 'tiene', 'en', 'cuenta', ',', 'por', 'otra', 'paite', ',', 'las', 'iniciativas', 'para', 'luchar', 'contra', 'esta', 'clase', 'de', 'discriminación', 'en', 'las', 'zonas', 'rurales', 'y', 'en', 'las', 'pequeñas', 'y', 'medianas', 'empresas', '.'], ['Siete', 'Estados', 'miembros', 'se', 'incluyen', 'en', 'el', 'proyecto', ':', 'Alemania', ',', 'Bélgica', ',', 'Francia', ',', 'Grecia', ',', 'Italia', ',', 'Países Bajos', 'y', 'Reino Unido', '.'], ['Resumen', 'del', 'EPAR', 'para', 'el', 'público', 'general', 'En', 'el', 'presente', 'documento', 'se', 'resume', 'el', 'Informe', 'Público', 'Europeo', 'de', 'Evaluación', ',', 'y', 'se', 'explica', 'cómo', 'la', 'evaluación', 'del', 'Comité', 'de', 'Medicamentos', 'de', 'Uso', 'Veterinario', '(', 'CVMP', ')', ',', 'efectuada', 'a partir de', 'los', 'estudios', 'existentes', ',', 'ha', 'llevado', 'a', 'las', 'recomendaciones', 'sobre', 'las', 'condiciones', 'de', 'uso', 'del', 'medicamento', '.'], ['¿Qué', 'es', 'Cerenia', '?'], ['Cerenia', 'contiene', 'el', 'principio', 'activo', 'maropitant', 'y', 'se', 'presenta', 'en', 'forma', 'de', 'comprimidos', 'o', 'de', 'solución', 'inyectables', '.'], ['Los', 'comprimidos', 'son', 'de', 'color', 'naranja', 'claro', 'y', 'tienen', 'una', 'ranura', 'en', 'ambas', 'caras', ',', 'lo', 'que', 'permite', 'dividirlos', 'por', 'la', 'mitad', '.'], ['Cada', 'comprimido', 'va', 'marcado', 'con', 'el', 'logo', 'Pfizer', 'en', 'una', 'cara', 'y', 'las', 'letras', 'MPT', 'y', 'la', 'cantidad', 'de', 'maropitant', 'en', 'la', 'otra', '.'], ['¿Para', 'qué', 'se', 'utiliza', 'Cerenia', '?'], ['Cerenia', 'es', 'un', 'antiemético', '(', 'ataja', 'los', 'vómitos', ')', '.'], ['Se', 'utiliza', 'en', 'perros', 'para', 'la', 'prevención', 'de', 'los', 'vómitos', ',', 'por ejemplo', 'los', 'causados', 'por', 'la', 'quimioterapia', '(', 'fármacos', 'utilizados', 'para', 'el', 'tratamiento', 'del', 'cáncer', ',', 'algunos', 'de', 'los', 'cuales', 'producen', 'vómitos', ')', '.'], ['Combinado', 'con', 'otras', 'medidas', 'complementarias', ',', 'como', 'otros', 'tratamientos', 'veterinarios', 'o', 'una', 'dieta', 'especial', ',', 'Cerenia', 'se', 'utiliza', 'también', 'como', 'tratamiento', 'del', 'vómito', '(', 'como', 'inyección', 'o', 'como', 'inyección', 'seguida', 'de', 'comprimidos', ')', '.'], ['A', 'estos', 'efectos', ',', 'Cerenia', 'se', 'puede', 'administrar', 'durante', 'un', 'período', 'de', 'hasta', 'cinco', 'días', '.'], ['¿Cómo', 'actúa', 'Cerenia', '?'], ['Cerenia', 'bloquea', 'los', 'receptores', 'de', 'neurocinina', '1', '(', 'NK1', ')', 'en', 'el', 'sistema', 'nervioso', 'central', '.'], ['¿Qué', 'tipo', 'de', 'estudios', 'se', 'han', 'realizado', 'sobre', 'Cerenia', '?'], ['Se', 'han', 'realizado', 'una', 'gran', 'cantidad', 'de', 'estudios', 'con', 'Cerenia', 'en', 'perros', 'de', 'laboratorio', 'y', 'en', 'perros', 'pacientes', 'de', 'clínicas', 'veterinarias', 'de', 'varios', 'países', 'europeos', 'y', 'de', 'EE.UU.'], ['¿Qué', 'beneficios', 'ha', 'demostrado', 'Cerenia', 'durante', 'dichos', 'estudios', '?'], ['Los', 'resultados', 'de', 'los', 'estudios', 'demostraron', 'que', 'Cerenia', 'fue', 'más', 'eficaz', 'que', 'el', 'placebo', ':', 'se', 'observaron', 'menos', 'vómitos', 'en', 'los', 'perros', 'que', 'recibieron', 'el', 'medicamento', 'que', 'en', 'los', 'perros', 'que', 'recibieron', 'placebo', ',', 'bien', 'como', 'tratamiento', ',', 'bien', 'como', 'prevención', 'del', 'vómito', '.'], ['El', 'tratamiento', 'de', 'un', 'perro', 'con', 'vómitos', 'debe', 'iniciarse', 'en', 'forma', 'inyectable', 'puesto que', 'los', 'animales', 'con', 'vómitos', 'podrían', 'no', 'retener', 'el', 'comprimido', '(', 'podrían', 'vomitar', 'el', 'comprimido', 'intacto', ')', '.'], ['Para', 'la', 'continuación', 'del', 'tratamiento', ',', 'el', 'propietario', 'puede', 'administrar', 'el', 'medicamento', 'al', 'animal', 'en', 'forma', 'de', 'comprimidos', '.'], ['El', 'tratamiento', 'del', 'vómito', 'debe', 'realizarse', 'siempre', 'en', 'asociación', 'con', 'otras', 'medidas', 'de', 'apoyo', 'u', 'otros', 'tratamientos', 'veterinarios', 'para', 'combatir', 'también', 'la', 'causa', 'subyacente', 'del', 'vómito', '.'], ['¿Cuáles', 'son', 'los', 'efectos', 'secundarios', 'de', 'Cerenia', '?'], ['En general', ',', 'Cerenia', 'fue', 'bien', 'tolerado', 'cuando', 'se', 'administró', 'diariamente', 'a', 'dosis', 'de', 'hasta', '5', 'veces', 'la', 'dosis', 'recomendada', 'durante', 'un', 'período', 'de', 'tiempo', 'prolongado', '(', 'hasta', '3', 'veces', 'la', 'duración', 'máxima', 'recomendada', 'del', 'tratamiento', ')', '.'], ['¿Qué', 'precauciones', 'debe', 'adoptar', 'la', 'persona', 'que', 'administre', 'el', 'medicamento', 'o', 'esté', 'en', 'contacto', 'con', 'el', 'animal', '?'], ['Cerenia', 'no', 'presenta', 'ningún', 'riesgo', 'especial', 'para', 'el', 'ser', 'humano', '.']]\n"
     ]
    }
   ],
   "source": [
    "idxes = raw_sense_df['Token ID'].tolist()\n",
    "tokens = raw_sense_df['Token'].tolist()\n",
    "# # print(idxes,tokens)\n",
    "en_sents = []\n",
    "pre_sid = None\n",
    "sent = []\n",
    "for i, s in zip(idxes, tokens):\n",
    "    if s != \"-end-\":\n",
    "        sent.append(s)\n",
    "    else:\n",
    "        en_sents.append(sent)\n",
    "        sent = []\n",
    "\n",
    "\n",
    "idxes = tkns_df['Token ID'].tolist()\n",
    "tokens = tkns_df['Token'].tolist()\n",
    "\n",
    "tgt_sents = []\n",
    "pre_sid = None\n",
    "sent = []\n",
    "for i, s in zip(idxes, tokens):\n",
    "    if s != \"-end-\":\n",
    "        sent.append(s)\n",
    "    else:\n",
    "        tgt_sents.append(sent)\n",
    "        sent = []\n",
    "print(len(en_sents),len(tgt_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "289f3807b810c81e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:57.722481Z",
     "start_time": "2024-09-14T08:05:57.654812Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'document', 'is', 'a', 'summary', 'of', 'the', 'European', 'Public', 'Assessment', 'Report', '(', 'EPAR', ')', '.']\n",
      "['En', 'el', 'presente', 'documento', 'se', 'resume', 'el', 'Informe', 'Público', 'Europeo', 'de', 'Evaluación', '(', 'EPAR', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "print(en_sents[0])\n",
    "print(tgt_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d6f1f0ac368d047",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:06:49.098343Z",
     "start_time": "2024-09-14T08:05:57.675362Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [01:25<00:00,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# do the alignment\n",
    "aligns = []\n",
    "for en_s, tgt_s in zip(tqdm(en_sents), tgt_sents):\n",
    "    # print(en_s,tgt_s,'\\n')\n",
    "    alignments = aligner.get_word_aligns(en_s, tgt_s)\n",
    "    align = ''\n",
    "    for w1, w2 in alignments[mode]:\n",
    "        align += f'{w1}-{w2} '\n",
    "    align = align.strip()\n",
    "    aligns.append(align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfce3cfa0a1f17d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:09.358582Z",
     "start_time": "2024-09-14T08:07:09.342625Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0-0 4-9 7-2 8-3 10-5 11-6 12-7 13-8 14-9 14-10'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9f6bf5b055261f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:09.529477Z",
     "start_time": "2024-09-14T08:07:09.514786Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>English-Spanish Alignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d000.s000</td>\n",
       "      <td>En el presente documento se resume el Informe ...</td>\n",
       "      <td>0-2 1-3 2-4 6-6 7-9 8-8 9-11 10-7 11-12 12-13 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d000.s001</td>\n",
       "      <td>En él se explica cómo el Comité de Medicamento...</td>\n",
       "      <td>0-1 1-3 2-4 3-5 4-6 5-7 6-8 6-11 7-8 8-9 9-11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d000.s002</td>\n",
       "      <td>Si desea más información sobre su enfermedad o...</td>\n",
       "      <td>0-0 2-1 3-2 4-3 5-4 6-5 8-6 9-7 11-9 12-13 13-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d000.s003</td>\n",
       "      <td>Si desea más información sobre el fundamento e...</td>\n",
       "      <td>0-0 2-1 3-2 4-3 5-4 6-5 7-6 10-16 11-14 12-17 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d000.s004</td>\n",
       "      <td>¿Qué es Alimta ?</td>\n",
       "      <td>0-0 1-1 2-2 3-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>d000.s116</td>\n",
       "      <td>El tratamiento del vómito debe realizarse siem...</td>\n",
       "      <td>0-20 2-0 3-1 4-2 5-3 6-4 7-6 8-5 9-8 10-9 11-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>d000.s117</td>\n",
       "      <td>¿Cuáles son los efectos secundarios de Cerenia ?</td>\n",
       "      <td>0-0 1-1 2-2 3-3 5-5 6-6 7-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>d000.s118</td>\n",
       "      <td>En general , Cerenia fue bien tolerado cuando ...</td>\n",
       "      <td>0-2 1-3 2-0 3-4 4-5 5-6 6-8 7-9 8-10 9-11 11-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>d000.s119</td>\n",
       "      <td>¿Qué precauciones debe adoptar la persona que ...</td>\n",
       "      <td>0-0 3-1 5-4 6-5 7-6 8-7 9-8 10-9 11-10 12-11 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>d000.s120</td>\n",
       "      <td>Cerenia no presenta ningún riesgo especial par...</td>\n",
       "      <td>0-0 2-1 3-2 4-7 5-5 6-4 7-6 8-9 9-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                           Sentence  \\\n",
       "0    d000.s000  En el presente documento se resume el Informe ...   \n",
       "1    d000.s001  En él se explica cómo el Comité de Medicamento...   \n",
       "2    d000.s002  Si desea más información sobre su enfermedad o...   \n",
       "3    d000.s003  Si desea más información sobre el fundamento e...   \n",
       "4    d000.s004                                   ¿Qué es Alimta ?   \n",
       "..         ...                                                ...   \n",
       "116  d000.s116  El tratamiento del vómito debe realizarse siem...   \n",
       "117  d000.s117   ¿Cuáles son los efectos secundarios de Cerenia ?   \n",
       "118  d000.s118  En general , Cerenia fue bien tolerado cuando ...   \n",
       "119  d000.s119  ¿Qué precauciones debe adoptar la persona que ...   \n",
       "120  d000.s120  Cerenia no presenta ningún riesgo especial par...   \n",
       "\n",
       "                             English-Spanish Alignment  \n",
       "0    0-2 1-3 2-4 6-6 7-9 8-8 9-11 10-7 11-12 12-13 ...  \n",
       "1    0-1 1-3 2-4 3-5 4-6 5-7 6-8 6-11 7-8 8-9 9-11 ...  \n",
       "2    0-0 2-1 3-2 4-3 5-4 6-5 8-6 9-7 11-9 12-13 13-...  \n",
       "3    0-0 2-1 3-2 4-3 5-4 6-5 7-6 10-16 11-14 12-17 ...  \n",
       "4                                      0-0 1-1 2-2 3-3  \n",
       "..                                                 ...  \n",
       "116  0-20 2-0 3-1 4-2 5-3 6-4 7-6 8-5 9-8 10-9 11-1...  \n",
       "117                        0-0 1-1 2-2 3-3 5-5 6-6 7-7  \n",
       "118  0-2 1-3 2-0 3-4 4-5 5-6 6-8 7-9 8-10 9-11 11-1...  \n",
       "119  0-0 3-1 5-4 6-5 7-6 8-7 9-8 10-9 11-10 12-11 1...  \n",
       "120               0-0 2-1 3-2 4-7 5-5 6-4 7-6 8-9 9-10  \n",
       "\n",
       "[121 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(aligns))\n",
    "trans_df['English-'+language+' Alignment'] = aligns\n",
    "trans_df.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1399438fa263261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:09.886812Z",
     "start_time": "2024-09-14T08:07:09.733501Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans_df.to_csv(ALIGN_SENT_FILE, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6729b5a32fd85f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T00:26:58.685090Z",
     "start_time": "2024-07-20T00:26:58.668497Z"
    },
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7912a9624f4b8438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T00:26:59.328824Z",
     "start_time": "2024-07-20T00:26:59.273476Z"
    },
    "collapsed": false
   },
   "source": [
    "# ALIGN TOKENS IN TOKEN FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f494bb7b47b2faa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:10.361932Z",
     "start_time": "2024-09-14T08:07:10.276442Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>BN Synset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>En</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>el</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d000.s000.t000</td>\n",
       "      <td>presente</td>\n",
       "      <td>presente</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>bn:00108977a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d000.s000.t001</td>\n",
       "      <td>documento</td>\n",
       "      <td>documento</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bn:00028015n;bn:00028017n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>se</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token ID      Token      Lemma   POS                  BN Synset\n",
       "0             NaN         En        NaN     X                        NaN\n",
       "1             NaN         el        NaN     X                        NaN\n",
       "2  d000.s000.t000   presente   presente   ADJ               bn:00108977a\n",
       "3  d000.s000.t001  documento  documento  NOUN  bn:00028015n;bn:00028017n\n",
       "4             NaN         se        NaN     X                        NaN"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b05842023dacc1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:10.433980Z",
     "start_time": "2024-09-14T08:07:10.354678Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>BN Synset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>This</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d000.s000.t000</td>\n",
       "      <td>document</td>\n",
       "      <td>document</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bn:00028015n;wiki:document;wn:document%1:10:00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d000.s000.t001</td>\n",
       "      <td>summary</td>\n",
       "      <td>summary</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bn:00075142n;wiki:summary_(law);wn:sum-up%1:10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token ID     Token     Lemma   POS  \\\n",
       "0             NaN      This       NaN     X   \n",
       "1  d000.s000.t000  document  document  NOUN   \n",
       "2             NaN        is        be  VERB   \n",
       "3             NaN         a       NaN     X   \n",
       "4  d000.s000.t001   summary   summary  NOUN   \n",
       "\n",
       "                                           BN Synset  \n",
       "0                                                NaN  \n",
       "1  bn:00028015n;wiki:document;wn:document%1:10:00...  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4  bn:00075142n;wiki:summary_(law);wn:sum-up%1:10...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_tks_df = pd.read_csv(RAW_SENSE_TSV, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "aligned_tks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf87633624b64662",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:10.680530Z",
     "start_time": "2024-09-14T08:07:10.487987Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aligned_tks_df['Token ID '+tgt_lan] = None\n",
    "aligned_tks_df['Token '+tgt_lan] = None\n",
    "aligned_tks_df['Lemma '+tgt_lan] = None\n",
    "aligned_tks_df['POS '+tgt_lan] = None\n",
    "aligned_tks_df['Sense '+tgt_lan] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96cb23c1328bebd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:10.818745Z",
     "start_time": "2024-09-14T08:07:10.662567Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2759\n"
     ]
    }
   ],
   "source": [
    "aligned_tks_df.head()\n",
    "print(len(aligned_tks_df['Token']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a7cf5efede63ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:10.966484Z",
     "start_time": "2024-09-14T08:07:10.822999Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>English-Spanish Alignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d000.s000</td>\n",
       "      <td>En el presente documento se resume el Informe ...</td>\n",
       "      <td>0-2 1-3 2-4 6-6 7-9 8-8 9-11 10-7 11-12 12-13 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d000.s001</td>\n",
       "      <td>En él se explica cómo el Comité de Medicamento...</td>\n",
       "      <td>0-1 1-3 2-4 3-5 4-6 5-7 6-8 6-11 7-8 8-9 9-11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d000.s002</td>\n",
       "      <td>Si desea más información sobre su enfermedad o...</td>\n",
       "      <td>0-0 2-1 3-2 4-3 5-4 6-5 8-6 9-7 11-9 12-13 13-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d000.s003</td>\n",
       "      <td>Si desea más información sobre el fundamento e...</td>\n",
       "      <td>0-0 2-1 3-2 4-3 5-4 6-5 7-6 10-16 11-14 12-17 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d000.s004</td>\n",
       "      <td>¿Qué es Alimta ?</td>\n",
       "      <td>0-0 1-1 2-2 3-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                           Sentence  \\\n",
       "0  d000.s000  En el presente documento se resume el Informe ...   \n",
       "1  d000.s001  En él se explica cómo el Comité de Medicamento...   \n",
       "2  d000.s002  Si desea más información sobre su enfermedad o...   \n",
       "3  d000.s003  Si desea más información sobre el fundamento e...   \n",
       "4  d000.s004                                   ¿Qué es Alimta ?   \n",
       "\n",
       "                           English-Spanish Alignment  \n",
       "0  0-2 1-3 2-4 6-6 7-9 8-8 9-11 10-7 11-12 12-13 ...  \n",
       "1  0-1 1-3 2-4 3-5 4-6 5-7 6-8 6-11 7-8 8-9 9-11 ...  \n",
       "2  0-0 2-1 3-2 4-3 5-4 6-5 8-6 9-7 11-9 12-13 13-...  \n",
       "3  0-0 2-1 3-2 4-3 5-4 6-5 7-6 10-16 11-14 12-17 ...  \n",
       "4                                    0-0 1-1 2-2 3-3  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d27a48d2ff0f089a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:11.168820Z",
     "start_time": "2024-09-14T08:07:11.029797Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_nan(s):\n",
    "  if type(s)!=type(''):\n",
    "    return ''\n",
    "  return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0335593",
   "metadata": {},
   "source": [
    "Run the below alignment if using the English/Original files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d9a577bd69e0209",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:14.404985Z",
     "start_time": "2024-09-14T08:07:11.215237Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 0\n",
      "error 0\n",
      "error 0\n",
      "error 0\n",
      "error 0\n",
      "error 0\n",
      "error 0\n",
      "error 0\n",
      "error 0\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 4\n",
      "error 4\n",
      "error 4\n",
      "error 4\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 6\n",
      "error 6\n",
      "error 6\n",
      "error 6\n",
      "error 7\n",
      "error 7\n",
      "error 7\n",
      "error 7\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 11\n",
      "error 11\n",
      "error 11\n",
      "error 11\n",
      "error 11\n",
      "error 11\n",
      "error 12\n",
      "error 12\n",
      "error 12\n",
      "error 12\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 18\n",
      "error 18\n",
      "error 18\n",
      "error 18\n",
      "error 18\n",
      "error 18\n",
      "error 18\n",
      "error 18\n",
      "error 18\n",
      "error 19\n",
      "error 19\n",
      "error 19\n",
      "error 19\n",
      "error 19\n",
      "error 19\n",
      "error 19\n",
      "error 19\n",
      "error 19\n",
      "error 20\n",
      "error 20\n",
      "error 20\n",
      "error 20\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 23\n",
      "error 23\n",
      "error 23\n",
      "error 23\n",
      "error 23\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 25\n",
      "error 25\n",
      "error 25\n",
      "error 25\n",
      "error 25\n",
      "error 25\n",
      "error 25\n",
      "error 25\n",
      "error 25\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 28\n",
      "error 28\n",
      "error 28\n",
      "error 28\n",
      "error 28\n",
      "error 28\n",
      "error 28\n",
      "error 28\n",
      "error 28\n",
      "error 29\n",
      "error 29\n",
      "error 29\n",
      "error 29\n",
      "error 29\n",
      "error 29\n",
      "error 29\n",
      "error 30\n",
      "error 30\n",
      "error 30\n",
      "error 30\n",
      "error 30\n",
      "error 30\n",
      "error 30\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 43\n",
      "error 43\n",
      "error 43\n",
      "error 43\n",
      "error 43\n",
      "error 43\n",
      "error 43\n",
      "error 43\n",
      "error 43\n",
      "error 43\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 45\n",
      "error 45\n",
      "error 45\n",
      "error 45\n",
      "error 45\n",
      "error 45\n",
      "error 45\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 48\n",
      "error 48\n",
      "error 48\n",
      "error 48\n",
      "error 48\n",
      "error 48\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 50\n",
      "error 50\n",
      "error 50\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 52\n",
      "error 52\n",
      "error 52\n",
      "error 52\n",
      "error 52\n",
      "error 52\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 54\n",
      "error 54\n",
      "error 54\n",
      "error 54\n",
      "error 54\n",
      "error 54\n",
      "error 54\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 57\n",
      "error 57\n",
      "error 58\n",
      "error 58\n",
      "error 58\n",
      "error 58\n",
      "error 59\n",
      "error 59\n",
      "error 60\n",
      "error 60\n",
      "error 60\n",
      "error 60\n",
      "error 60\n",
      "error 61\n",
      "error 61\n",
      "error 61\n",
      "error 61\n",
      "error 61\n",
      "error 61\n",
      "error 61\n",
      "error 62\n",
      "error 63\n",
      "error 63\n",
      "error 63\n",
      "error 63\n",
      "error 63\n",
      "error 63\n",
      "error 63\n",
      "error 63\n",
      "error 63\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 65\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 67\n",
      "error 68\n",
      "error 68\n",
      "error 68\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 70\n",
      "error 70\n",
      "error 70\n",
      "error 70\n",
      "error 70\n",
      "error 70\n",
      "error 70\n",
      "error 70\n",
      "error 70\n",
      "error 71\n",
      "error 71\n",
      "error 71\n",
      "error 71\n",
      "error 71\n",
      "error 71\n",
      "error 71\n",
      "error 71\n",
      "error 71\n",
      "error 71\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 73\n",
      "error 73\n",
      "error 73\n",
      "error 73\n",
      "error 73\n",
      "error 73\n",
      "error 74\n",
      "error 74\n",
      "error 74\n",
      "error 74\n",
      "error 74\n",
      "error 74\n",
      "error 75\n",
      "error 75\n",
      "error 75\n",
      "error 75\n",
      "error 76\n",
      "error 76\n",
      "error 76\n",
      "error 76\n",
      "error 76\n",
      "error 76\n",
      "error 76\n",
      "error 76\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 78\n",
      "error 78\n",
      "error 78\n",
      "error 78\n",
      "error 78\n",
      "error 78\n",
      "error 78\n",
      "error 78\n",
      "error 78\n",
      "error 79\n",
      "error 79\n",
      "error 79\n",
      "error 79\n",
      "error 79\n",
      "error 79\n",
      "error 79\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 82\n",
      "error 82\n",
      "error 82\n",
      "error 82\n",
      "error 82\n",
      "error 82\n",
      "error 82\n",
      "error 82\n",
      "error 82\n",
      "error 82\n",
      "error 83\n",
      "error 83\n",
      "error 83\n",
      "error 83\n",
      "error 83\n",
      "error 83\n",
      "error 83\n",
      "error 83\n",
      "error 83\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 88\n",
      "error 88\n",
      "error 88\n",
      "error 88\n",
      "error 88\n",
      "error 88\n",
      "error 88\n",
      "error 88\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 91\n",
      "error 91\n",
      "error 91\n",
      "error 91\n",
      "error 91\n",
      "error 91\n",
      "error 91\n",
      "error 91\n",
      "error 91\n",
      "error 91\n",
      "error 92\n",
      "error 92\n",
      "error 92\n",
      "error 92\n",
      "error 92\n",
      "error 92\n",
      "error 92\n",
      "error 92\n",
      "error 92\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 95\n",
      "error 95\n",
      "error 95\n",
      "error 95\n",
      "error 95\n",
      "error 95\n",
      "error 95\n",
      "error 95\n",
      "error 95\n",
      "error 95\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 99\n",
      "error 99\n",
      "error 99\n",
      "error 99\n",
      "error 100\n",
      "error 100\n",
      "error 100\n",
      "error 100\n",
      "error 100\n",
      "error 100\n",
      "error 100\n",
      "error 101\n",
      "error 101\n",
      "error 101\n",
      "error 101\n",
      "error 101\n",
      "error 101\n",
      "error 101\n",
      "error 101\n",
      "error 101\n",
      "error 101\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 103\n",
      "error 103\n",
      "error 103\n",
      "error 104\n",
      "error 104\n",
      "error 104\n",
      "error 104\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 107\n",
      "error 107\n",
      "error 107\n",
      "error 107\n",
      "error 107\n",
      "error 107\n",
      "error 107\n",
      "error 107\n",
      "error 107\n",
      "error 107\n",
      "error 108\n",
      "error 108\n",
      "error 108\n",
      "error 108\n",
      "error 108\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 110\n",
      "error 110\n",
      "error 110\n",
      "error 110\n",
      "error 110\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 112\n",
      "error 112\n",
      "error 112\n",
      "error 112\n",
      "error 112\n",
      "error 112\n",
      "error 112\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 115\n",
      "error 115\n",
      "error 115\n",
      "error 115\n",
      "error 115\n",
      "error 115\n",
      "error 115\n",
      "error 115\n",
      "error 115\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 117\n",
      "error 117\n",
      "error 117\n",
      "error 117\n",
      "error 117\n",
      "error 117\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 120\n",
      "error 120\n",
      "error 120\n",
      "error 120\n",
      "error 120\n",
      "error 120\n"
     ]
    }
   ],
   "source": [
    "count_en = 0\n",
    "sentence_num = 0\n",
    "count_es = 0\n",
    "for i, row in trans_df.iterrows():\n",
    "    # print(row.iloc[0])\n",
    "    sent_i = row.iloc[0]\n",
    "    # print(sent_i)\n",
    "    # print(sent_i)\n",
    "    tgt_sent_i = sent_i\n",
    "    # print(row)\n",
    "    # sent_i = sent_i.replace(\"i\",\"d\")\n",
    "    # tgt_sent = tkns_df.loc[count_es:count_es+len(tgt_sents[sentence_num])]\n",
    "    # en_sent = aligned_tks_df.loc[count_en:count_en+len(en_sents[sentence_num])]\n",
    "    # print(tgt_sent.loc[2])\n",
    "    # print(row)\n",
    "    for alignment in row['English-'+language+' Alignment'].split():\n",
    "        try:\n",
    "            w1, w2 = alignment.split('-')\n",
    "            \n",
    "            en_id = f'{sent_i}.t{int(w1) + 1:03d}'\n",
    "            tgt_id = f'{tgt_sent_i}.t{int(w2) + 1:03d}'\n",
    "            row_en = aligned_tks_df[aligned_tks_df['Token ID'] == en_id]\n",
    "            row_tgt = tkns_df[tkns_df['Token ID'] == tgt_id]\n",
    "            # print(row_tgt)\n",
    "    \n",
    "            # print(aligned_tks_df['Token ID'] )\n",
    "            # print(row_tgt)\n",
    "            # print(row_en.iloc[0]['Token ID '+tgt_lan])\n",
    "            if row_en.iloc[0]['Token ID '+tgt_lan] is not None:\n",
    "                aligned_tks_df.loc[row_en.index, 'Token ID '+tgt_lan] += '➕' + row_tgt.iloc[0]['Token ID']\n",
    "                aligned_tks_df.loc[row_en.index, 'Token '+tgt_lan] += '➕' + row_tgt.iloc[0]['Token']\n",
    "                if aligned_tks_df.loc[row_en.index, 'POS '+tgt_lan].item() != process_nan(row_tgt.iloc[0]['POS']):\n",
    "                    aligned_tks_df.loc[row_en.index, 'POS '+tgt_lan] += '➕' + process_nan(row_tgt.iloc[0]['POS'])\n",
    "                if aligned_tks_df.loc[row_en.index, 'Sense '+tgt_lan].item() != process_nan(row_en.iloc[0]['BN Synset']):\n",
    "                    aligned_tks_df.loc[row_en.index, 'Sense '+tgt_lan] += '➕' + process_nan(str(row_en.iloc[0]['BN Synset']).split(\";\")[0])\n",
    "            else:\n",
    "                # print(str(row_en.iloc[0]['BN Synset']).split(\";\")[0])\n",
    "                # print(row_tgt.iloc[0]['Token ID'])\n",
    "                # print(row_en.index.values)\n",
    "                aligned_tks_df.loc[row_en.index.values[0], 'Token ID '+tgt_lan] = row_tgt.iloc[0]['Token ID']\n",
    "                # print(aligned_tks_df.loc[row_en.index, 'Token ID '+tgt_lan],row_tgt.iloc[0]['Token ID'],'\\\\n\\\\n')\n",
    "        \n",
    "                aligned_tks_df.loc[row_en.index.values[0], 'Token '+tgt_lan] = row_tgt.iloc[0]['Token']\n",
    "                aligned_tks_df.loc[row_en.index.values[0], 'Lemma '+tgt_lan] = row_tgt.iloc[0]['Lemma']\n",
    "                aligned_tks_df.loc[row_en.index.values[0], 'POS '+tgt_lan] = row_tgt.iloc[0]['POS']\n",
    "                aligned_tks_df.loc[row_en.index.values[0], 'Sense '+tgt_lan] = str(row_en.iloc[0]['BN Synset']).split(\";\")[0]\n",
    "                aligned_tks_df.loc[row_en.index.values[0], 'BN Synset'] = str(row_en.iloc[0]['BN Synset']).split(\";\")[0]\n",
    "        except:\n",
    "            print(f\"error {i}\")\n",
    "    # count_en += len(en_sents[sentence_num])\n",
    "    # count_es += len(tgt_sents[sentence_num])\n",
    "    # sentence_num += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aed5746",
   "metadata": {},
   "source": [
    "Run the below for alignment if you are using the provided English/second-sense files and the Spanish or Italian provided files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ae5b20f4241c471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:14.412437Z",
     "start_time": "2024-09-14T08:07:14.406443Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_en = 0\n",
    "sentence_num = 0\n",
    "count_es = 0\n",
    "for i, row in trans_df.iterrows():\n",
    "    # print(row.iloc[0])\n",
    "    sent_i = row.iloc[0]\n",
    "    # print(sent_i)\n",
    "    # print(sent_i)\n",
    "    tgt_sent_i = sent_i\n",
    "    # print(row)\n",
    "    # sent_i = sent_i.replace(\"i\",\"d\")\n",
    "    tgt_sent = tkns_df.loc[count_es:count_es+len(tgt_sents[sentence_num])]\n",
    "    en_sent = aligned_tks_df.loc[count_en:count_en+len(en_sents[sentence_num])]\n",
    "    # print(tgt_sent.loc[2])\n",
    "    # print(row)\n",
    "    for alignment in row['English-'+language+' Alignment'].split():\n",
    "        w1, w2 = alignment.split('-')\n",
    "        row_tgt = tgt_sent.loc[count_es+int(w2)]\n",
    "        row_en = en_sent.loc[count_en+int(w1)]\n",
    "        if row_en['Token ID '+tgt_lan] is not None:\n",
    "            if str(aligned_tks_df.loc[count_en+int(w1), 'Token ID '+tgt_lan]) != \"nan\":\n",
    "                aligned_tks_df.loc[count_en+int(w1), 'Token ID '+tgt_lan] += '➕' + str(row_tgt['Token ID'])\n",
    "            else:\n",
    "                aligned_tks_df.loc[count_en+int(w1), 'Token ID '+tgt_lan] = str(row_tgt['Token ID'])\n",
    "            aligned_tks_df.loc[count_en+int(w1), 'Token '+tgt_lan] += '➕' + row_tgt['Token']\n",
    "            if aligned_tks_df.loc[count_en+int(w1), 'POS '+tgt_lan] != process_nan(row_tgt['POS']):\n",
    "                aligned_tks_df.loc[count_en+int(w1), 'POS '+tgt_lan] += '➕' + process_nan(row_tgt['POS'])\n",
    "            if aligned_tks_df.loc[count_en+int(w1), 'Sense '+tgt_lan] != process_nan(row_en['BN Synset']):\n",
    "                if str(aligned_tks_df.loc[count_en+int(w1), 'Sense '+tgt_lan]) != \"nan\":\n",
    "                    aligned_tks_df.loc[count_en+int(w1), 'Sense '+tgt_lan] += '➕' + process_nan(row_en['BN Synset'])\n",
    "        else:\n",
    "            aligned_tks_df.loc[count_en+int(w1), 'Token ID '+tgt_lan] = row_tgt['Token ID']\n",
    "            aligned_tks_df.loc[count_en+int(w1), 'Token '+tgt_lan] = row_tgt['Token']\n",
    "            aligned_tks_df.loc[count_en+int(w1), 'Lemma '+tgt_lan] = row_tgt[\"Lemma\"]\n",
    "            aligned_tks_df.loc[count_en+int(w1), 'POS '+tgt_lan] = row_tgt['POS']\n",
    "            aligned_tks_df.loc[count_en+int(w1), 'Sense '+tgt_lan] = row_en['BN Synset']\n",
    "\n",
    "    count_en += len(en_sents[sentence_num])\n",
    "    count_es += len(tgt_sents[sentence_num])\n",
    "    sentence_num += 1\n",
    "    # print(count_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3762e840ae06d384",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:14.421818Z",
     "start_time": "2024-09-14T08:07:14.417067Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>BN Synset</th>\n",
       "      <th>Token ID ES</th>\n",
       "      <th>Token ES</th>\n",
       "      <th>Lemma ES</th>\n",
       "      <th>POS ES</th>\n",
       "      <th>Sense ES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>This</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d000.s000.t000</td>\n",
       "      <td>presente</td>\n",
       "      <td>presente</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d000.s000.t000</td>\n",
       "      <td>document</td>\n",
       "      <td>document</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bn:00028015n;wiki:document;wn:document%1:10:00...</td>\n",
       "      <td>d000.s000.t001</td>\n",
       "      <td>documento</td>\n",
       "      <td>documento</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bn:00028015n;wiki:document;wn:document%1:10:00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>se</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d000.s000.t001</td>\n",
       "      <td>summary</td>\n",
       "      <td>summary</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bn:00075142n</td>\n",
       "      <td>d000.s000.t003</td>\n",
       "      <td>Informe</td>\n",
       "      <td>informe</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bn:00075142n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-end-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d000.s086.t005</td>\n",
       "      <td>caso</td>\n",
       "      <td>caso</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>For</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>detallado</td>\n",
       "      <td>detallar</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>each</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>d000.s086.t000</td>\n",
       "      <td>country</td>\n",
       "      <td>country</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bn:00011771n;bn:00023235n;wiki:country;wiki:so...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>estos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>bn:00011771n;bn:00023235n;wiki:country;wiki:so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Token ID     Token     Lemma   POS  \\\n",
       "0                NaN      This       NaN     X   \n",
       "1     d000.s000.t000  document  document  NOUN   \n",
       "2                NaN        is        be  VERB   \n",
       "3                NaN         a       NaN     X   \n",
       "4     d000.s000.t001   summary   summary  NOUN   \n",
       "...              ...       ...       ...   ...   \n",
       "1995             NaN     -end-       NaN     X   \n",
       "1996             NaN       For       NaN     X   \n",
       "1997             NaN      each       NaN     X   \n",
       "1998  d000.s086.t000   country   country  NOUN   \n",
       "1999             NaN         ,       NaN     X   \n",
       "\n",
       "                                              BN Synset     Token ID ES  \\\n",
       "0                                                   NaN  d000.s000.t000   \n",
       "1     bn:00028015n;wiki:document;wn:document%1:10:00...  d000.s000.t001   \n",
       "2                                                   NaN             NaN   \n",
       "3                                                   NaN            None   \n",
       "4                                          bn:00075142n  d000.s000.t003   \n",
       "...                                                 ...             ...   \n",
       "1995                                                NaN  d000.s086.t005   \n",
       "1996                                                NaN             NaN   \n",
       "1997                                                NaN            None   \n",
       "1998  bn:00011771n;bn:00023235n;wiki:country;wiki:so...             NaN   \n",
       "1999                                                NaN            None   \n",
       "\n",
       "       Token ES   Lemma ES POS ES  \\\n",
       "0      presente   presente    ADJ   \n",
       "1     documento  documento   NOUN   \n",
       "2            se        NaN      X   \n",
       "3          None       None   None   \n",
       "4       Informe    informe   NOUN   \n",
       "...         ...        ...    ...   \n",
       "1995       caso       caso   NOUN   \n",
       "1996  detallado   detallar   VERB   \n",
       "1997       None       None   None   \n",
       "1998      estos        NaN      X   \n",
       "1999       None       None   None   \n",
       "\n",
       "                                               Sense ES  \n",
       "0                                                   NaN  \n",
       "1     bn:00028015n;wiki:document;wn:document%1:10:00...  \n",
       "2                                                   NaN  \n",
       "3                                                  None  \n",
       "4                                          bn:00075142n  \n",
       "...                                                 ...  \n",
       "1995                                                NaN  \n",
       "1996                                                NaN  \n",
       "1997                                               None  \n",
       "1998  bn:00011771n;bn:00023235n;wiki:country;wiki:so...  \n",
       "1999                                               None  \n",
       "\n",
       "[2000 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aligned_tks_df[]\n",
    "aligned_tks_df.head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5368fae50b58bf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:14.468480Z",
     "start_time": "2024-09-14T08:07:14.423068Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aligned_tks_df.to_csv(ALIGN_TOKEN_FILE, sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
