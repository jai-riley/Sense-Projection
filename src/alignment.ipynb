{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install hanlp\n",
    "# !pip install simalign\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb406a76c0f6d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:03:07.734747Z",
     "start_time": "2024-09-14T08:03:01.773665Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os, csv\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from simalign import SentenceAligner\n",
    "# from google.cloud import translate_v2 as translate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612df192",
   "metadata": {},
   "source": [
    "Below is a working example using the provided data files.\n",
    "To align Italian and Spanish to English, using the files in the 'second-sense' folder. Otherwise, use the files in the 'Original' folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b13fc3dfe5421d25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:47.113938Z",
     "start_time": "2024-09-14T08:05:47.070873Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "src_lan = 'en'\n",
    "# target language\n",
    "tgt_lan = 'BN'\n",
    "language = \"Bengali\"\n",
    "\n",
    "RESOURCE = '~/Desktop/Research/Sense-Projection'\n",
    "DATA =  RESOURCE+'/data/'+language\n",
    "TRANS_FILE = os.path.join(DATA, 'gold-sentences-'+language+'.tsv')\n",
    "TOKENS_FILE = os.path.join(DATA, language+'-Gold.tsv')\n",
    "ALIGN_SENT_FILE = os.path.join(DATA, 'sentences-aligned-'+language+'.tsv')\n",
    "ALIGN_TOKEN_FILE = os.path.join(DATA, 'tokens-aligned-'+language+'.tsv')\n",
    "\n",
    "# DATA = os.path.join(RESOURCE, 'data')\n",
    "DATA =  RESOURCE+'/data/English/Original/'\n",
    "\n",
    "KEY = os.path.join(RESOURCE, 'key')\n",
    "RAW_SENSE_TSV = os.path.join(DATA, 'gold-tokens-English-wSenses.tsv')\n",
    "RAW_SENTENCE_TSV = os.path.join(DATA, 'gold-sentences-English.tsv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c6865ff265fa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T00:25:20.160408Z",
     "start_time": "2024-07-20T00:25:20.081626Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b00d2748a93fc3cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:47.469676Z",
     "start_time": "2024-09-14T08:05:47.430137Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2525\n"
     ]
    }
   ],
   "source": [
    "# raw\n",
    "raw_sense_df = pd.read_csv(RAW_SENSE_TSV, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "raw_sense_df.head()\n",
    "print(len(raw_sense_df['Token'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f042be62c8de0a8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:47.706594Z",
     "start_time": "2024-09-14T08:05:47.681398Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jairiley/Desktop/Research/Sense-Projection/data/English/Original/gold-sentences-English.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sentence_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRAW_SENTENCE_TSV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQUOTE_NONE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m sentence_df\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m      3\u001b[0m sents \u001b[38;5;241m=\u001b[39m sentence_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/jairiley/Desktop/Research/Sense-Projection/data/English/Original/gold-sentences-English.tsv'"
     ]
    }
   ],
   "source": [
    "sentence_df = pd.read_csv(RAW_SENTENCE_TSV, delimiter='\\t',  quoting=csv.QUOTE_NONE)\n",
    "sentence_df.head()\n",
    "sents = sentence_df[\"ID\"].tolist()\n",
    "len(sents)\n",
    "# print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a52ea439706c5fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:47.816258Z",
     "start_time": "2024-09-14T08:05:47.808935Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n"
     ]
    }
   ],
   "source": [
    "sids = sentence_df[\"ID\"].tolist()\n",
    "# sids = [i.replace('d', 'i') for i in sids]\n",
    "# sids[:4]\n",
    "print(len(sids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86ef027023e515d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:48.052992Z",
     "start_time": "2024-09-14T08:05:48.028191Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jairiley/Desktop/Research/Sense-Projection/data/Bengali/gold-sentences-Bengali.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trans_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRANS_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQUOTE_NONE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m trans_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/jairiley/Desktop/Research/Sense-Projection/data/Bengali/gold-sentences-Bengali.tsv'"
     ]
    }
   ],
   "source": [
    "trans_df = pd.read_csv(TRANS_FILE, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f432a89a379c822",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:48.275751Z",
     "start_time": "2024-09-14T08:05:48.215503Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>BN Synset</th>\n",
       "      <th>Gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d001.s001.t001</td>\n",
       "      <td>এই</td>\n",
       "      <td>এই</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d001.s001.t002</td>\n",
       "      <td>নথিটি</td>\n",
       "      <td>নথি</td>\n",
       "      <td>N</td>\n",
       "      <td>bn:00028015n</td>\n",
       "      <td>Writing that provides information (especially ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d001.s001.t003</td>\n",
       "      <td>ইউরোপীয়</td>\n",
       "      <td>ইউরোপ</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d001.s001.t004</td>\n",
       "      <td>পাবলিক</td>\n",
       "      <td>পাবলিক</td>\n",
       "      <td>A</td>\n",
       "      <td>bn:00109211a</td>\n",
       "      <td>Not private; open to or concerning the people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d001.s001.t005</td>\n",
       "      <td>অ্যাসেসমেন্ট</td>\n",
       "      <td>অ্যাসেসমেন্ট</td>\n",
       "      <td>N</td>\n",
       "      <td>bn:00006502n</td>\n",
       "      <td>The act of judging or assessing a person or si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>d002.s020.t022</td>\n",
       "      <td>গণ্য</td>\n",
       "      <td>গণ্য</td>\n",
       "      <td>V</td>\n",
       "      <td>bn:00095141v</td>\n",
       "      <td>Regard or consider in a specific way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>d002.s020.t023</td>\n",
       "      <td>হবে</td>\n",
       "      <td>হবে</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>d002.s020.t024</td>\n",
       "      <td>।</td>\n",
       "      <td>।</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>d002.s021.t001</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>d002.s021.t002</td>\n",
       "      <td>#ERROR!</td>\n",
       "      <td>#ERROR!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Token ID         Token         Lemma  POS     BN Synset  \\\n",
       "0    d001.s001.t001            এই            এই    X           NaN   \n",
       "1    d001.s001.t002         নথিটি           নথি    N  bn:00028015n   \n",
       "2    d001.s001.t003      ইউরোপীয়         ইউরোপ    N           NaN   \n",
       "3    d001.s001.t004        পাবলিক        পাবলিক    A  bn:00109211a   \n",
       "4    d001.s001.t005  অ্যাসেসমেন্ট  অ্যাসেসমেন্ট    N  bn:00006502n   \n",
       "..              ...           ...           ...  ...           ...   \n",
       "995  d002.s020.t022          গণ্য          গণ্য    V  bn:00095141v   \n",
       "996  d002.s020.t023           হবে           হবে    V           NaN   \n",
       "997  d002.s020.t024             ।             ।    X           NaN   \n",
       "998  d002.s021.t001             :             :    X           NaN   \n",
       "999  d002.s021.t002       #ERROR!       #ERROR!  NaN           NaN   \n",
       "\n",
       "                                                 Gloss  \n",
       "0                                                  NaN  \n",
       "1    Writing that provides information (especially ...  \n",
       "2                                                  NaN  \n",
       "3    Not private; open to or concerning the people ...  \n",
       "4    The act of judging or assessing a person or si...  \n",
       "..                                                 ...  \n",
       "995               Regard or consider in a specific way  \n",
       "996                                                NaN  \n",
       "997                                                NaN  \n",
       "998                                                NaN  \n",
       "999                                                NaN  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkns_df = pd.read_csv(TOKENS_FILE, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "tkns_df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "657283dde5c279c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:48.520729Z",
     "start_time": "2024-09-14T08:05:48.427681Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2287"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_tkns = tkns_df['Token'].tolist()\n",
    "len(tgt_tkns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c7b3b3697f3f04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T00:25:29.100491Z",
     "start_time": "2024-07-20T00:25:29.088726Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# ALIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bfcface1251e192",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:57.634596Z",
     "start_time": "2024-09-14T08:05:48.993979Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2025-09-09 15:37:24,297 - simalign.simalign - INFO - Initialized the EmbeddingLoader with model: xlm-roberta-base\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "layer = 8\n",
    "# \"bert\": \"bert-base-multilingual-cased\",\n",
    "# \"xlmr\": \"xlm-roberta-base\"\n",
    "model = 'xlmr'\n",
    "# mwmf (Match), inter (ArgMax), itermax (IterMax)\n",
    "mode = 'inter'\n",
    "matching_methods = 'mai'\n",
    "token_type='bpe'\n",
    "aligner = SentenceAligner(\n",
    "    model=model\n",
    "    , token_type=token_type\n",
    "    , matching_methods=matching_methods\n",
    "    , layer=layer\n",
    "    , device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5963d6746fecc939",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:57.652105Z",
     "start_time": "2024-09-14T08:05:57.639785Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>BN Synset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d001.s001.t001</td>\n",
       "      <td>This</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d001.s001.t002</td>\n",
       "      <td>document</td>\n",
       "      <td>document</td>\n",
       "      <td>N</td>\n",
       "      <td>bn:00028015n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d001.s001.t003</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d001.s001.t004</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d001.s001.t005</td>\n",
       "      <td>summary</td>\n",
       "      <td>summary</td>\n",
       "      <td>N</td>\n",
       "      <td>bn:00075142n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token ID     Token     Lemma POS     BN Synset\n",
       "0  d001.s001.t001      This       NaN   X           NaN\n",
       "1  d001.s001.t002  document  document   N  bn:00028015n\n",
       "2  d001.s001.t003        is        be   V           NaN\n",
       "3  d001.s001.t004         a       NaN   X           NaN\n",
       "4  d001.s001.t005   summary   summary   N  bn:00075142n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_sense_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55570ec",
   "metadata": {},
   "source": [
    "Run the below cell only if using the files in the English/Original directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bb827932bd9b23f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:57.687254Z",
     "start_time": "2024-09-14T08:05:57.648963Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tkns_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m         s\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[1;32m     16\u001b[0m en_sents\u001b[38;5;241m.\u001b[39mappend(s)\n\u001b[0;32m---> 19\u001b[0m idxes \u001b[38;5;241m=\u001b[39m \u001b[43mtkns_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mToken ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     20\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tkns_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mToken\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     22\u001b[0m tgt_sents \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tkns_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "idxes = raw_sense_df['Token ID'].tolist()\n",
    "tokens = raw_sense_df['Token'].tolist()\n",
    "en_sents = []\n",
    "pre_sid = None\n",
    "s = []\n",
    "for i, t in zip(idxes, tokens):\n",
    "    # print(i)\n",
    "    sid = i.split('.')[1]\n",
    "    if sid != pre_sid:\n",
    "        if s:\n",
    "            en_sents.append(s)\n",
    "        pre_sid = sid\n",
    "        s = [t]\n",
    "    else:\n",
    "        s.append(t)\n",
    "en_sents.append(s)\n",
    "\n",
    "\n",
    "idxes = tkns_df['Token ID'].tolist()\n",
    "tokens = tkns_df['Token'].tolist()\n",
    "\n",
    "tgt_sents = []\n",
    "pre_sid = None\n",
    "s = []\n",
    "for i, t in zip(idxes, tokens):\n",
    "    sid = i.split('.')[1]\n",
    "    if sid != pre_sid:\n",
    "        if s:\n",
    "            tgt_sents.append(s)\n",
    "        pre_sid = sid\n",
    "        s = [t]\n",
    "    else:\n",
    "        s.append(t)\n",
    "tgt_sents.append(s)\n",
    "\n",
    "print(len(en_sents),len(tgt_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c859b938",
   "metadata": {},
   "source": [
    "Run the below cell only if you are using the files in the English/second-sense directory as well as the provided Spanish or Italian files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a35f146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "[['En', 'el', 'presente', 'documento', 'se', 'resume', 'el', 'Informe', 'Público', 'Europeo', 'de', 'Evaluación', '(', 'EPAR', ')', '.'], ['En', 'él', 'se', 'explica', 'cómo', 'el', 'Comité', 'de', 'Medicamentos', 'de', 'Uso', 'Humano', '(', 'CHMP', ')', 'ha', 'evaluado', 'los', 'estudios', 'realizados', 'con', 'el', 'medicamento', 'a fin de', 'emitir', 'unas', 'recomendaciones', 'sobre', 'su', 'uso', '.'], ['Si', 'desea', 'más', 'información', 'sobre', 'su', 'enfermedad', 'o', 'el', 'tratamiento', 'de', 'la', 'misma', ',', 'le', 'aconsejamos', 'que', 'lea', 'el', 'prospecto', '(', 'incluido', 'en', 'el', 'EPAR', ')', 'o', 'pregunte', 'a', 'su', 'médico', 'o', 'su', 'farmacéutico', '.'], ['Si', 'desea', 'más', 'información', 'sobre', 'el', 'fundamento', 'en', 'el', 'que', 'se', 'han', 'basado', 'las', 'recomendaciones', 'del', 'CHMP', ',', 'le', 'aconsejamos', 'que', 'lea', 'el', 'Debate', 'Científico', '(', 'también', 'incluido', 'en', 'el', 'EPAR', ')', '.'], ['¿Qué', 'es', 'Alimta', '?'], ['Alimta', 'es', 'un', 'polvo', 'con', 'el', 'que', 'se', 'prepara', 'una', 'solución', 'para', 'perfusión', '(', 'goteo', 'en', 'vena', ')', '.'], ['Contiene', 'el', 'principio', 'activo', 'pemetrexed', '.'], ['¿Para', 'qué', 'se', 'utiliza', 'Alimta', '?'], ['Alimta', 'está', 'indicado', 'para', 'el', 'tratamiento', 'de', 'dos', 'tipos', 'de', 'cáncer', ':', 'mesotelioma', 'pleural', '(', 'cáncer', 'del', 'revestimiento', 'de', 'los', 'pulmones', 'causado', 'generalmente', 'por', 'la', 'exposición', 'al', 'amianto', ')', '.'], ['Alimta', 'se', 'administra', 'en', 'combinación', 'con', 'cisplatino', '(', 'otro', 'medicamento', 'contra', 'el', 'cáncer', ')', 'cuando', 'el', 'tumor', '«', 'no', 'es', 'resecable', '»', '(', 'no', 'puede', 'extirparse', 'sólo', 'mediante', 'cirugía', ')', 'y', 'es', '«', 'maligno', '»', '(', 'se', 'ha', 'extendido', ',', 'o', 'es', 'probable', 'que', 'se', 'extienda', 'fácilmente', ',', 'a', 'otras', 'partes', 'del', 'cuerpo', ')', ',', 'en', 'pacientes', 'que', 'no', 'han', 'recibido', 'quimioterapia', '(', 'medicamentos', 'contra', 'el', 'cáncer', ')', 'previamente', ',', 'cáncer', 'de', 'pulmón', '«', 'no', 'microcítico', '»', 'avanzado', 'o', 'metastásico', 'que', 'no', 'afecte', 'a', 'las', 'células', '«', 'escamosas', '»', '.'], ['Alimta', 'se', 'utiliza', 'en', 'combinación', 'con', 'cisplatino', 'en', 'pacientes', 'que', 'no', 'han', 'sido', 'tratados', 'previamente', 'y', 'en', 'monoterapia', 'en', 'pacientes', 'que', 'han', 'sido', 'tratado', 'previamente', 'con', 'otros', 'tipos', 'de', 'quimioterapia', '.'], ['Este', 'medicamento', 'sólo', 'podrá', 'dispensarse', 'con', 'receta', 'médica', '.'], ['¿Cómo', 'se', 'usa', 'Alimta', '?'], ['Alimta', 'sólo', 'debe', 'administrarse', 'bajo', 'la', 'supervisión', 'de', 'un', 'médico', 'cualificado', 'en', 'el', 'uso', 'de', 'quimioterapia', 'contra', 'el', 'cáncer', '.'], ['La', 'dosis', 'recomendada', 'de', 'Alimta', 'es', 'de', '500', 'mg', 'por', 'metro', 'cuadrado', 'de', 'superficie', 'corporal', '(', 'calculada', 'a partir de', 'la', 'estatura', 'y', 'el', 'peso', 'del', 'paciente', ')', '.', 'Se', 'administra', 'una', 'vez', 'cada', 'tres', 'semanas', 'por', 'perfusión', 'intravenosa', 'durante', '10', 'minutos', '.'], ['Con', 'el', 'fin', 'de', 'reducir', 'los', 'efectos', 'secundarios', ',', 'los', 'pacientes', 'deben', 'recibir', 'un', 'corticosteroide', 'y', 'ácido', 'fólico', '(', 'un', 'tipo', 'de', 'vitamina', ')', ',', 'así como', 'inyecciones', 'de', 'vitamina', 'B12', 'durante', 'el', 'tratamiento', 'con', 'Alimta', '.'], ['Cuando', 'Alimta', 'se', 'utiliza', 'conjuntamente', 'con', 'cisplatino', ',', 'hay que', 'administrar', 'además', 'un', 'medicamento', '«', 'antiemético', '»', '(', 'para', 'evitar', 'los', 'vómitos', ')', 'y', 'líquidos', '(', 'para', 'evitar', 'la', 'deshidratación', ')', 'antes', 'o', 'después de', 'la', 'dosis', 'de', 'cisplatino', '.'], ['Será', 'necesario', 'retrasar', 'o', 'suspender', 'el', 'tratamiento', ',', 'o', 'reducir', 'la', 'dosis', ',', 'en', 'pacientes', 'que', 'presenten', 'alteraciones', 'en', 'los', 'recuentos', 'sanguíneos', 'o', 'determinados', 'efectos', 'secundarios', '.'], ['No', 'se', 'recomienda', 'administrar', 'Alimta', 'a', 'pacientes', 'con', 'problemas', 'renales', 'moderados', 'o', 'graves', '.'], ['Si', 'desea', 'más', 'información', ',', 'consulte', 'el', 'Resumen', 'de', 'las', 'Características', 'del', 'Producto', ',', 'que', 'también', 'forma', 'parte', 'del', 'EPAR', '.'], ['¿Cómo', 'actúa', 'Alimta', '?'], ['El', 'principio', 'activo', 'de', 'Alimta', ',', 'el', 'pemetrexed', ',', 'es', 'un', 'medicamento', 'citotóxico', '(', 'un', 'medicamento', 'que', 'destruye', 'las', 'células', 'que', 'están', 'en', 'fase', 'de', 'división', ',', 'como', 'las', 'cancerosas', ')', 'que', 'pertenece', 'al', 'grupo', 'de', 'los', '«', 'antimetabolitos', '»', '.'], ['En', 'el', 'organismo', ',', 'el', 'pemetrexed', 'se', 'convierte', 'en', 'una', 'forma', 'activa', 'que', 'bloquea', 'la', 'actividad', 'de', 'las', 'enzimas', 'que', 'participan', 'en', 'la', 'producción', 'de', '«', 'nucleótidos', '»', '(', 'elementos', 'esenciales', 'del', 'ADN', 'y', 'el', 'ARN', ',', 'el', 'material', 'genético', 'de', 'las', 'células', ')', '.'], ['¿Qué', 'tipo', 'de', 'estudios', 'se', 'han', 'realizado', 'con', 'Alimta', '?'], ['Por', 'lo', 'que', 'se', 'refiere', 'al', 'tratamiento', 'del', 'mesotelioma', 'pleural', 'maligno', ',', 'Alimta', 'ha', 'sido', 'evaluado', 'en', 'un', 'estudio', 'principal', 'realizado', 'en', '456', 'pacientes', 'que', 'no', 'habían', 'recibido', 'quimioterapia', 'anteriormente', '.'], ['Se', 'compararon', 'los', 'efectos', 'de', 'Alimta', 'en', 'combinación', 'con', 'cisplatino', 'con', 'los', 'efectos', 'del', 'cisplatino', 'administrado', 'en', 'solitario', '.'], ['En', 'cuanto', 'al', 'tratamiento', 'del', 'cáncer', 'de', 'pulmón', 'no', 'microcítico', ',', 'se', 'compararon', 'los', 'efectos', 'de', 'Alimta', 'con', 'los', 'del', 'docetaxel', '(', 'otro', 'medicamento', 'contra', 'el', 'cáncer', ')', 'en', 'un', 'estudio', 'realizado', 'en', '571', 'pacientes', 'con', 'enfermedad', 'localmente', 'avanzada', 'o', 'metastásica', 'que', 'habían', 'recibido', 'quimioterapia', 'previamente', '.'], ['Alimta', 'también', 'se', 'comparó', 'con', 'gemcitabina', '(', 'otro', 'medicamento', 'contra', 'el', 'cáncer', ')', ',', 'ambos', 'en', 'combinación', 'con', 'cisplatino', ',', 'en', 'un', 'estudio', 'con', '1.725', 'pacientes', 'que', 'no', 'habían', 'recibido', 'quimioterapia', 'contra', 'el', 'cáncer', 'de', 'pulmón', 'previamente', '.'], ['En', 'los', 'tres', 'estudios', ',', 'el', 'criterio', 'principal', 'de', 'valoración', 'de', 'la', 'eficacia', 'fue', 'el', 'tiempo', 'de', 'supervivencia', 'de', 'los', 'pacientes', '.'], ['¿Qué', 'beneficio', 'ha', 'demostrado', 'tener', 'Alimta', 'durante', 'los', 'estudios', '?'], ['Alimta', 'prolongó', 'el', 'tiempo', 'de', 'supervivencia', 'de', 'los', 'pacientes', 'con', 'mesotelioma', 'pleural', 'maligno', '.'], ['Los', 'pacientes', 'que', 'recibieron', 'Alimta', 'y', 'cisplatino', 'sobrevivieron', 'una', 'media', 'de', '12,1', 'meses', ',', 'mientras que', 'la', 'supervivencia', 'de', 'los', 'enfermos', 'tratados', 'sólo', 'con', 'cisplatino', 'fue', 'de', '9,3', 'meses', '.'], ['En', 'el', 'tratamiento', 'de', 'pacientes', 'con', 'cáncer', 'de', 'pulmón', 'no', 'microcítico', ',', 'Alimta', 'fue', 'tan', 'efectivo', 'como', 'los', 'medicamentos', 'de', 'comparación', '.'], ['En', 'los', 'pacientes', 'que', 'habían', 'recibido', 'quimioterapia', 'previamente', ',', 'el', 'tiempo', 'medio', 'de', 'supervivencia', 'fue', 'de', '8,3', 'meses', 'con', 'Alimta', 'frente a', '7,9', 'meses', 'con', 'docetaxel', '.'], ['En', 'pacientes', 'que', 'no', 'habían', 'recibido', 'previamente', 'quimioterapia', ',', 'el', 'tiempo', 'medio', 'de', 'supervivencia', 'fue', 'de', '10,3', 'meses', 'en', 'ambos', 'grupos', '.'], ['No obstante', ',', 'los', 'pacientes', 'de', 'ambos', 'estudios', 'cuyo', 'cáncer', 'no', 'afectaba', 'a', 'las', 'células', 'escamosas', 'presentaban', 'un', 'mayor', 'tiempo', 'de', 'supervivencia', 'cuando', 'recibían', 'Alimta', 'que', 'cuando', 'recibían', 'el', 'medicamento', 'de', 'comparación', '.'], ['Por el contrario', ',', 'los', 'pacientes', 'cuyo', 'cáncer', 'estaba', 'afectando', 'a', 'las', 'células', 'escamosas', 'presentaron', 'tiempos', 'de', 'supervivencia', 'más', 'breve', 'si', 'se', 'les', 'trataba', 'con', 'Alimta', '.', 'kalgebra', 'es', 'una', 'calculadora', 'matemática', 'basada', 'en', 'el', 'lenguaje', 'de', 'marcado', 'MathML', '.'], ['Hoy', 'en', 'día', 'es', 'capaz', 'de', 'realizar', 'operaciones', 'simples', '(', 'aritméticas', 'y', 'lógicas', ')', 'usando', 'MathML', 'y', 'de', 'representarlas', 'en', 'gráficas', 'de', 'dos', 'y', 'tres', 'dimensiones', '.'], ['No', 'es', 'necesario', 'conocer', 'MathML', 'para', 'usar', 'kalgebra', '.', 'kalgebra', 'es', 'una', 'calculadora', 'gráfica', 'basada', 'en', 'MathML', '.'], ['Aunque', 'en', 'un', 'principio', 'estuvo', 'orientado', 'a', 'MathML', ',', 'actualmente', 'puede', 'ser', 'usado', 'por', 'cualquier', 'persona', ',', 'aunque', 'posea', 'pocos', 'conocimientos', 'matemáticos', '.'], ['Aquí', 'se', 'muestra', 'una', 'captura', 'de', 'la', 'ventana', 'principal', 'de', 'kalgebra', '.', 'Ventana', 'principal', 'de', 'kalgebra', 'La', 'ventana', 'principal', 'de', 'kalgebra', 'consta', 'de', 'cuatro', 'pestañas', ':', 'Consola', ',', 'Gráfica', '2D', ',', 'Gráfica', '3D', 'y', 'Diccionario', '.'], ['Bajo', 'estas', 'pestañas', 'encontrará', 'un', 'campo', 'de', 'entrada', 'donde', 'podrá', 'introducir', 'sus', 'funciones', 'o', 'realizar', 'sus', 'cálculos', '.'], ['Para', 'entender', 'cómo', 'funciona', ',', 'conviene', 'comprender', 'que', 'lo', 'que', 'introducimos', 'está', 'siendo', 'convertido', 'a', 'MathML', ',', 'aunque', 'no', 'es', 'necesario', 'conocer', 'MathML', '.'], ['He', 'basado', 'la', 'sintaxis', 'en', 'el', 'sentido', 'común', ',', 'por', 'lo', 'que', 'debería', 'ser', 'asequible', 'para', 'todos', '.'], ['He', 'tenido', 'también', 'en', 'cuenta', 'las', 'sintaxis', 'de', 'Maxima', 'y', 'Maple', ',', 'por', 'lo', 'que', 'es', 'muy', 'similar', 'a', 'estas', '.', '+', '-', '*', '/', ':', 'suma', ',', 'resta', ',', 'multiplicación', 'y', 'división', '.', '^', ',', '**', ':', 'potencia', ',', 'puede', 'usar', 'cualquiera', 'de', 'las', 'dos', 'formas', '.'], ['Asimismo', ',', 'puede', 'usar', 'los', 'caracteres', 'unicode', '²', '.'], ['Las', 'potencias', 'son', 'también', 'una', 'forma', 'de', 'expresar', 'raíces', '.', '-gt', ':', 'Permite', 'especificar', 'la', 'variable', 'limitada', 'en', 'una', 'función', '.', '(', ')', ':', 'se', 'usa', 'para', 'especificar', 'una', 'prioridad', 'mayor', '.', 'abc(parámetros)', ':', 'Cuando', 'el', 'analizador', 'sintáctico', 'encuentra', 'una', 'función', ',', 'comprueba', 'si', '«', 'abc', '»', 'es', 'un', 'operador', '.'], ['Si', 'lo', 'es', ',', 'lo', 'trata', 'como', 'un', 'operador', 'si', 'no', 'lo', 'es', ',', 'lo', 'trata', 'como', 'una', 'función', 'de', 'usuario', '.', ':', '=', ':', 'Se', 'usa', 'para', 'definir', 'el', 'valor', 'de', 'una', 'variable', '.', '?', ':', 'definición', 'de', 'condiciones', 'en', 'funciones', 'definidas', 'a', 'trozos', '(', '«', 'piecewise', '»', ')', '.'], ['Permite', 'definir', 'operaciones', 'condicionales', 'en', 'kalgebra', '.'], ['Cuando', 'introducimos', 'la', 'condición', 'antes', 'del', 'símbolo', '«', '?', '»', ',', 'kalgebra', 'utiliza', 'esta', 'condición', 'solo', 'si', 'es', 'verdadera', 'en cambio', ',', 'si', 'encuentra', 'un', 'símbolo', '«', '?', '»', 'sin', 'ninguna', 'condición', ',', 'toma', 'en', 'cuenta', 'el', 'último', 'caso', '.', '{', '}', ':', 'Puede', 'usarse', 'para', 'definir', 'un', 'contenedor', '.'], ['Es', 'muy', 'útil', 'a', 'la', 'hora', 'de', 'trabajar', 'con', 'funciones', 'definidas', 'a', 'trozos', '.'], ['Ahora', 'puede', 'preguntarme', 'por qué', 'debería', 'el', 'usuario', 'preocuparse', 'por', 'MathML', '.', 'La', 'respuesta', 'es', 'fácil', '.', 'Con', 'esto', 'podremos', 'realizar', 'operaciones', 'con', 'funciones', 'como', 'cos()', ',', 'sin()', '(', 'o', 'cualquier', 'otra', 'función', 'trigonométrica', ')', ',', 'sum()', 'o', 'product()', '.'], ['No', 'importa', 'el', 'tipo', 'de', 'función', 'que', 'sea', '.'], ['Podremos', 'usar', 'plus()', ',', 'times()', 'y', 'cualquier', 'cosa', 'a la que', 'le', 'corresponda', 'un', 'operador', '.', 'La', 'consola', 'de', 'kalgebra', 'es', 'tan', 'útil', 'como', 'una', 'calculadora', '.'], ['Aquí', 'tiene', 'una', 'lista', 'de', 'las', 'variables', 'declaradas', '.'], ['Si', 'pulsa', 'dos', 'veces', 'sobre', 'una', 'de', 'ellas', ',', 'le', 'aparecerá', 'un', 'diálogo', 'con', 'el', 'que', 'podrá', 'cambiar', 'su', 'valor', '(', 'es', 'una', 'forma', 'de', 'engañar', 'al', 'registro', ')', '.'], ['Cada vez que', 'introduzca', 'una', 'expresión', ',', 'el', 'valor', 'de', 'la', 'variable', '«', 'ans', '»', 'cambiará', 'para', 'reproducir', 'el', 'último', 'resultado', '.'], ['Ctrl', 'N', 'Nuevo'], ['Refresca', 'el', 'registro', '.'], ['Ctrl', 'L', 'Cargar', 'un', 'guión'], ['Ejecuta', 'las', 'instrucciones', 'en', 'una', 'archivo', 'de', 'forma', 'secuencial', '.'], ['Es', 'útil', 'si', 'lo', 'que', 'desea', 'es', 'definir', 'una', 'biblioteca', 'o', 'reanudar', 'un', 'trabajo', 'anterior', '.'], ['Ctrl', 'G', 'Guardar', 'el', 'guión'], ['Guarda', 'las', 'intrucciones', 'que', 'ha', 'introducido', 'desde', 'que', 'comenzó', 'la', 'sesión', ',', 'con', 'lo', 'que', 'podrá', 'reutilizarlas', '.'], ['Genera', 'un', 'archivo', 'de', 'texto', 'que', 'podrá', 'corregir', 'usando', 'cualquier', 'editor', 'de', 'texto', ',', 'por ejemplo', 'Kate', '.'], ['Ctrl', 'S', 'Guardar', 'el', 'registro'], ['Guarda', 'el', 'registro', 'con', 'todos', 'los', 'resultados', 'en', 'un', 'archivo', 'HTML', 'que', 'podrá', 'imprimir', 'o', 'publicar', '.'], ['Ctrl', 'Q', 'Salir'], ['Cierra', 'el', 'programa', '.'], ['Para', 'añadir', 'un', 'gráfica', '2D', 'en', 'kalgebra', ',', 'lo', 'que', 'tiene que', 'hacer', 'es', 'ir', 'a', 'la', 'pestaña', 'Gráfica', '2D', 'y', 'aquí', 'pulsar', 'la', 'pestaña', 'Añadir', ',', 'que', 'le', 'permitirá', 'añadir', 'una', 'nueva', 'función', '.'], ['A', 'continuación', 'tendrá', 'dirigirse', 'al', 'cuadro', 'de', 'texto', 'de', 'entrada', ',', 'donde', 'podrá', 'introducir', 'su', 'función', '.'], ['Si', 'quiere', 'usar', 'una', 'función', 'f(x)', 'típica', ',', 'no', 'es', 'necesario', 'que', 'la', 'especifique', '.'], ['Después de', 'haber', 'introducido', 'la', 'función', ',', 'pulse', 'el', 'botón', 'Aceptar', 'para', 'dibujar', 'la', 'gráfica', 'en', 'la', 'ventana', 'principal', '.'], ['Es', 'posible', 'dibujar', 'varias', 'gráficas', 'en', 'la', 'misma', 'vista', '.'], ['Para', 'esto', 'use', 'simplemente', 'el', 'botón', 'Añadir', 'cuando', 'se', 'encuentre', 'en', 'el', 'modo', 'Lista', '.'], ['Puede', 'ajustar', 'el', 'color', 'de', 'cada', 'gráfica', '.'], ['La', 'Fundación', 'ha', 'intervenido', 'recientemente', 'en', 'la', 'organización', 'de', 'una', 'conferencia', 'sobre', 'este', 'decisivo', 'reto', '.'], ['Asistieron', 'más', 'de', '100', 'participantes', 'en', 'representación', 'de', 'los', 'principales', 'grupos', 'de', 'interés', ',', 'los', 'cuales', 'discutieron', 'cuestiones', 'tales', 'como', 'el', 'papel', 'de', 'los', 'principales', 'agentes', ',', 'entre', 'ellos', ',', 'las', 'autoridades', 'públicas', ',', 'los', 'interlocutores', 'sociales', 'y', 'las', 'organizaciones', 'comunitarias', 'y', 'de', 'voluntarios', ',', 'además', 'de', 'los', 'propios', 'usuarios', '.'], ['Se', 'llegó', 'a', 'la', 'conclusión', 'de', 'que', 'es', 'necesario', 'adoptar', 'un', 'enfoque', 'más', 'global', 'que', 'tenga en cuenta', 'que', 'los', 'usuarios', 'no', 'se', 'sirven', 'de', 'esos', 'servicios', 'de', 'forma', 'aislada', ',', 'sino', 'como', 'parte', 'de', 'su', 'vida', 'cotidiana', '.'], ['Se', 'tomó', 'nota', 'también', 'de', 'la', 'diversidad', 'de', 'funciones', 'que', 'desempeñan', 'estos', 'servicios'], ['La', 'Fundación', 'organizó', ',', 'junto con', 'la', 'Comisión', 'Europea', ',', 'el', 'Ministerio', 'español', 'de', 'Asuntos', 'Sociales', 'y', 'la', 'Comunidad', 'Autónoma', 'de', 'Galicia', ',', 'una', 'conferencia', 'europea', 'sobre', 'el', 'tema', '\"\"\"\"', 'Exclusión', 'social', ':', 'Un', 'gran', 'reto', 'para', 'los', 'servicios', 'públicos', 'de', 'protección', 'social', '\"\"\"\"', '.'], ['La', 'Fundación', 'publicó', 'recientemente', 'en', 'el', 'marco', 'del', 'proyecto', 'EPOC', 'un', 'estudio', 'comparativo', 'en', 'el', 'que', 'se', 'evalúa', 'hasta', 'qué', 'punto', 'la', 'participación', 'directa', 'puede', 'humanizar', 'el', 'trabajo', 'e', 'incrementar', 'al mismo tiempo', 'la', 'rentabilidad', '.'], ['El', 'estudio', 'se', 'basa', 'en', '195', 'entrevistas', 'personales', 'con', 'altos', 'responsables', 'de', 'los', 'interlocutores', 'sociales', ',', 'en', 'su', 'calidad', 'de', 'representantes', 'de', 'importantes', 'organizaciones', 'nacionales', 'de', '15', 'países', 'europeos', '.'], ['La', 'industria', 'del', 'metal', 'y', 'el', 'sector', 'bancario', 'se', 'incluyeron', 'también', 'en', 'atención', 'a', 'su', 'importancia', '.'], ['Los', 'principales', 'oradores', 'en', 'la', 'conferencia', 'sobre', 'exclusión', 'socialfueron', '(', 'de', 'izquierda', 'a', 'derecha', ')', 'Cristina', 'Louro', ',', 'Dirección', 'General', 'de', 'Empleo', ',', 'Relaciones', 'Laborales', 'y', 'Asuntos', 'Sociales', 'de', 'la', 'Comisión', 'Europea', 'Fernando', 'Gomes', ',', 'Comité', 'de', 'las', 'Regiones', 'Barbara', 'Weiler', ',', 'diputada', 'al', 'Parlamento', 'Europeo', 'José', 'María', 'Gil-Robles', 'Gil-Delgado', ',', 'Vicepresidente', ',', 'Parlamento', 'Europeo', ',', 'John', 'Carroll', 'Comité', 'Económico', 'y', 'Social'], ['En', 'cada', 'informe', 'nacional', 'se', 'incluyen', 'las', '25', 'o', '30', 'iniciativas', 'que', 'mejor', 'reflejan', 'prácticas', 'y', 'políticas', 'de', 'mejora', 'de', 'la', 'contratación', ',', 'la', 'formación', 'y', 'el', 'desarrollo', 'profesional', 'de', 'los', 'trabajadores', 'mayores', 'en', 'el', 'lugar', 'de', 'trabajo', 'y', 'a nivel de', 'la', 'comunidad', '.'], ['Se', 'seleccionaron', 'dos', 'o', 'tres', 'iniciativas', 'por', 'cada', 'país', ',', 'para', 'que', 'fueran', 'objeto', 'de', 'un', 'estudio', 'de', 'caso', 'detallado', '.'], ['En', 'estos', 'estudios', 'de', 'caso', 'se', 'han', 'analizado', 'el', 'contexto', 'de', 'esas', 'iniciativas', 'y', 'sus', 'repercusiones', 'en', 'las', 'pautas', 'de', 'empleo', 'y', 'en', 'las', 'organizaciones', ',', 'y', 'se', 'han', 'evaluado', 'las', 'ventajas', 'y', 'problemas', 'derivados', 'de', 'las', 'mismas', '.'], ['Se', 'han', 'realizado', 'además', 'visitas', 'y', 'entrevistas', 'a', 'miembros', 'clave', 'del', 'personal', '.'], ['Estos', 'estudios', 'nacionales', 'constituirán', 'la', 'liase', 'de', 'un', 'informe', 'europeo', 'en', 'el', 'que', 'se', 'resumirán', 'las', 'prácticas', 'generales', '.'], ['El', 'informe', 'y', 'un', 'repertorio', 'de', 'iniciativas', 'se', 'publicarán', 'en', '1996', ',', 'y', 'servirán', 'de', 'telón', 'de', 'fondo', 'a', 'una', 'conferencia', 'que', 'se', 'celebrará', 'el', 'próximo', 'otoño', '.'], ['La', 'Fundación', 'se', 'propone', 'documentar', 'las', 'características', 'de', 'los', 'obstáculos', 'relacionados', 'con', 'la', 'edad', 'en', 'materia', 'de', 'contratación', 'y', 'formación', ',', 'y', 'analizar', 'sus', 'causas', '.'], ['Está', 'examinando', 'asimismo', 'los', 'puntos', 'de', 'vista', 'de', 'los', 'interlocutores', 'sociales', ',', 'prestando', 'especial', 'atención', 'a', 'las', 'propuestas', 'para', 'eliminar', 'dichos', 'obstáculos', '.'], ['En', 'tercer', 'lugar', ',', 'el', 'proyecto', 'documenta', 'y', 'evalúa', 'las', 'iniciativas', 'de', 'los', 'sectores', 'público', 'y', 'privado', 'para', 'combatir', 'estas', 'limitaciones', ',', 'especialmente', 'en relación con', 'los', 'trabajadores', 'mayores', '.'], ['El', 'proyecto', ',', 'que', 'busca', 'alternativas', 'a', 'la', 'jubilación', 'anticipada', 'y', 'al', 'despido', ',', 'se', 'ocupa', 'ante', 'todo', 'de', 'la', 'retención', ',', 'la', 'reintegración', 'y', 'la', 'reconversión', 'profesional', 'de', 'los', 'trabajadores', 'mayores', '.'], ['Estudia', 'asimismo', 'liasta', 'qué', 'punto', 'influyen', 'el', 'sexo', 'y', 'la', 'raza', 'de', 'los', 'trabajadores', 'en', 'la', 'discriminación', 'por', 'razón', 'de', 'la', 'edad', '.'], ['El', 'proyecto', 'tiene', 'en', 'cuenta', ',', 'por', 'otra', 'paite', ',', 'las', 'iniciativas', 'para', 'luchar', 'contra', 'esta', 'clase', 'de', 'discriminación', 'en', 'las', 'zonas', 'rurales', 'y', 'en', 'las', 'pequeñas', 'y', 'medianas', 'empresas', '.'], ['Siete', 'Estados', 'miembros', 'se', 'incluyen', 'en', 'el', 'proyecto', ':', 'Alemania', ',', 'Bélgica', ',', 'Francia', ',', 'Grecia', ',', 'Italia', ',', 'Países Bajos', 'y', 'Reino Unido', '.'], ['Resumen', 'del', 'EPAR', 'para', 'el', 'público', 'general', 'En', 'el', 'presente', 'documento', 'se', 'resume', 'el', 'Informe', 'Público', 'Europeo', 'de', 'Evaluación', ',', 'y', 'se', 'explica', 'cómo', 'la', 'evaluación', 'del', 'Comité', 'de', 'Medicamentos', 'de', 'Uso', 'Veterinario', '(', 'CVMP', ')', ',', 'efectuada', 'a partir de', 'los', 'estudios', 'existentes', ',', 'ha', 'llevado', 'a', 'las', 'recomendaciones', 'sobre', 'las', 'condiciones', 'de', 'uso', 'del', 'medicamento', '.'], ['¿Qué', 'es', 'Cerenia', '?'], ['Cerenia', 'contiene', 'el', 'principio', 'activo', 'maropitant', 'y', 'se', 'presenta', 'en', 'forma', 'de', 'comprimidos', 'o', 'de', 'solución', 'inyectables', '.'], ['Los', 'comprimidos', 'son', 'de', 'color', 'naranja', 'claro', 'y', 'tienen', 'una', 'ranura', 'en', 'ambas', 'caras', ',', 'lo', 'que', 'permite', 'dividirlos', 'por', 'la', 'mitad', '.'], ['Cada', 'comprimido', 'va', 'marcado', 'con', 'el', 'logo', 'Pfizer', 'en', 'una', 'cara', 'y', 'las', 'letras', 'MPT', 'y', 'la', 'cantidad', 'de', 'maropitant', 'en', 'la', 'otra', '.'], ['¿Para', 'qué', 'se', 'utiliza', 'Cerenia', '?'], ['Cerenia', 'es', 'un', 'antiemético', '(', 'ataja', 'los', 'vómitos', ')', '.'], ['Se', 'utiliza', 'en', 'perros', 'para', 'la', 'prevención', 'de', 'los', 'vómitos', ',', 'por ejemplo', 'los', 'causados', 'por', 'la', 'quimioterapia', '(', 'fármacos', 'utilizados', 'para', 'el', 'tratamiento', 'del', 'cáncer', ',', 'algunos', 'de', 'los', 'cuales', 'producen', 'vómitos', ')', '.'], ['Combinado', 'con', 'otras', 'medidas', 'complementarias', ',', 'como', 'otros', 'tratamientos', 'veterinarios', 'o', 'una', 'dieta', 'especial', ',', 'Cerenia', 'se', 'utiliza', 'también', 'como', 'tratamiento', 'del', 'vómito', '(', 'como', 'inyección', 'o', 'como', 'inyección', 'seguida', 'de', 'comprimidos', ')', '.'], ['A', 'estos', 'efectos', ',', 'Cerenia', 'se', 'puede', 'administrar', 'durante', 'un', 'período', 'de', 'hasta', 'cinco', 'días', '.'], ['¿Cómo', 'actúa', 'Cerenia', '?'], ['Cerenia', 'bloquea', 'los', 'receptores', 'de', 'neurocinina', '1', '(', 'NK1', ')', 'en', 'el', 'sistema', 'nervioso', 'central', '.'], ['¿Qué', 'tipo', 'de', 'estudios', 'se', 'han', 'realizado', 'sobre', 'Cerenia', '?'], ['Se', 'han', 'realizado', 'una', 'gran', 'cantidad', 'de', 'estudios', 'con', 'Cerenia', 'en', 'perros', 'de', 'laboratorio', 'y', 'en', 'perros', 'pacientes', 'de', 'clínicas', 'veterinarias', 'de', 'varios', 'países', 'europeos', 'y', 'de', 'EE.UU.'], ['¿Qué', 'beneficios', 'ha', 'demostrado', 'Cerenia', 'durante', 'dichos', 'estudios', '?'], ['Los', 'resultados', 'de', 'los', 'estudios', 'demostraron', 'que', 'Cerenia', 'fue', 'más', 'eficaz', 'que', 'el', 'placebo', ':', 'se', 'observaron', 'menos', 'vómitos', 'en', 'los', 'perros', 'que', 'recibieron', 'el', 'medicamento', 'que', 'en', 'los', 'perros', 'que', 'recibieron', 'placebo', ',', 'bien', 'como', 'tratamiento', ',', 'bien', 'como', 'prevención', 'del', 'vómito', '.'], ['El', 'tratamiento', 'de', 'un', 'perro', 'con', 'vómitos', 'debe', 'iniciarse', 'en', 'forma', 'inyectable', 'puesto que', 'los', 'animales', 'con', 'vómitos', 'podrían', 'no', 'retener', 'el', 'comprimido', '(', 'podrían', 'vomitar', 'el', 'comprimido', 'intacto', ')', '.'], ['Para', 'la', 'continuación', 'del', 'tratamiento', ',', 'el', 'propietario', 'puede', 'administrar', 'el', 'medicamento', 'al', 'animal', 'en', 'forma', 'de', 'comprimidos', '.'], ['El', 'tratamiento', 'del', 'vómito', 'debe', 'realizarse', 'siempre', 'en', 'asociación', 'con', 'otras', 'medidas', 'de', 'apoyo', 'u', 'otros', 'tratamientos', 'veterinarios', 'para', 'combatir', 'también', 'la', 'causa', 'subyacente', 'del', 'vómito', '.'], ['¿Cuáles', 'son', 'los', 'efectos', 'secundarios', 'de', 'Cerenia', '?'], ['En general', ',', 'Cerenia', 'fue', 'bien', 'tolerado', 'cuando', 'se', 'administró', 'diariamente', 'a', 'dosis', 'de', 'hasta', '5', 'veces', 'la', 'dosis', 'recomendada', 'durante', 'un', 'período', 'de', 'tiempo', 'prolongado', '(', 'hasta', '3', 'veces', 'la', 'duración', 'máxima', 'recomendada', 'del', 'tratamiento', ')', '.'], ['¿Qué', 'precauciones', 'debe', 'adoptar', 'la', 'persona', 'que', 'administre', 'el', 'medicamento', 'o', 'esté', 'en', 'contacto', 'con', 'el', 'animal', '?'], ['Cerenia', 'no', 'presenta', 'ningún', 'riesgo', 'especial', 'para', 'el', 'ser', 'humano', '.']]\n"
     ]
    }
   ],
   "source": [
    "idxes = raw_sense_df['Token ID'].tolist()\n",
    "tokens = raw_sense_df['Token'].tolist()\n",
    "# # print(idxes,tokens)\n",
    "en_sents = []\n",
    "pre_sid = None\n",
    "sent = []\n",
    "for i, s in zip(idxes, tokens):\n",
    "    if s != \"-end-\":\n",
    "        sent.append(s)\n",
    "    else:\n",
    "        en_sents.append(sent)\n",
    "        sent = []\n",
    "\n",
    "\n",
    "idxes = tkns_df['Token ID'].tolist()\n",
    "tokens = tkns_df['Token'].tolist()\n",
    "\n",
    "tgt_sents = []\n",
    "pre_sid = None\n",
    "sent = []\n",
    "for i, s in zip(idxes, tokens):\n",
    "    if s != \"-end-\":\n",
    "        sent.append(s)\n",
    "    else:\n",
    "        tgt_sents.append(sent)\n",
    "        sent = []\n",
    "print(len(en_sents),len(tgt_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "289f3807b810c81e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:05:57.722481Z",
     "start_time": "2024-09-14T08:05:57.654812Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'document', 'is', 'a', 'summary', 'of', 'the', 'European', 'Public', 'Assessment', 'Report', '(', 'EPAR', ')', '.']\n",
      "['En', 'el', 'presente', 'documento', 'se', 'resume', 'el', 'Informe', 'Público', 'Europeo', 'de', 'Evaluación', '(', 'EPAR', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "print(en_sents[0])\n",
    "print(tgt_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d6f1f0ac368d047",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:06:49.098343Z",
     "start_time": "2024-09-14T08:05:57.675362Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [01:25<00:00,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# do the alignment\n",
    "aligns = []\n",
    "for en_s, tgt_s in zip(tqdm(en_sents), tgt_sents):\n",
    "    # print(en_s,tgt_s,'\\n')\n",
    "    alignments = aligner.get_word_aligns(en_s, tgt_s)\n",
    "    align = ''\n",
    "    for w1, w2 in alignments[mode]:\n",
    "        align += f'{w1}-{w2} '\n",
    "    align = align.strip()\n",
    "    aligns.append(align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfce3cfa0a1f17d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:09.358582Z",
     "start_time": "2024-09-14T08:07:09.342625Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0-0 4-9 7-2 8-3 10-5 11-6 12-7 13-8 14-9 14-10'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9f6bf5b055261f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:09.529477Z",
     "start_time": "2024-09-14T08:07:09.514786Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>English-Spanish Alignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d000.s000</td>\n",
       "      <td>En el presente documento se resume el Informe ...</td>\n",
       "      <td>0-2 1-3 2-4 6-6 7-9 8-8 9-11 10-7 11-12 12-13 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d000.s001</td>\n",
       "      <td>En él se explica cómo el Comité de Medicamento...</td>\n",
       "      <td>0-1 1-3 2-4 3-5 4-6 5-7 6-8 6-11 7-8 8-9 9-11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d000.s002</td>\n",
       "      <td>Si desea más información sobre su enfermedad o...</td>\n",
       "      <td>0-0 2-1 3-2 4-3 5-4 6-5 8-6 9-7 11-9 12-13 13-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d000.s003</td>\n",
       "      <td>Si desea más información sobre el fundamento e...</td>\n",
       "      <td>0-0 2-1 3-2 4-3 5-4 6-5 7-6 10-16 11-14 12-17 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d000.s004</td>\n",
       "      <td>¿Qué es Alimta ?</td>\n",
       "      <td>0-0 1-1 2-2 3-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>d000.s116</td>\n",
       "      <td>El tratamiento del vómito debe realizarse siem...</td>\n",
       "      <td>0-20 2-0 3-1 4-2 5-3 6-4 7-6 8-5 9-8 10-9 11-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>d000.s117</td>\n",
       "      <td>¿Cuáles son los efectos secundarios de Cerenia ?</td>\n",
       "      <td>0-0 1-1 2-2 3-3 5-5 6-6 7-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>d000.s118</td>\n",
       "      <td>En general , Cerenia fue bien tolerado cuando ...</td>\n",
       "      <td>0-2 1-3 2-0 3-4 4-5 5-6 6-8 7-9 8-10 9-11 11-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>d000.s119</td>\n",
       "      <td>¿Qué precauciones debe adoptar la persona que ...</td>\n",
       "      <td>0-0 3-1 5-4 6-5 7-6 8-7 9-8 10-9 11-10 12-11 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>d000.s120</td>\n",
       "      <td>Cerenia no presenta ningún riesgo especial par...</td>\n",
       "      <td>0-0 2-1 3-2 4-7 5-5 6-4 7-6 8-9 9-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                           Sentence  \\\n",
       "0    d000.s000  En el presente documento se resume el Informe ...   \n",
       "1    d000.s001  En él se explica cómo el Comité de Medicamento...   \n",
       "2    d000.s002  Si desea más información sobre su enfermedad o...   \n",
       "3    d000.s003  Si desea más información sobre el fundamento e...   \n",
       "4    d000.s004                                   ¿Qué es Alimta ?   \n",
       "..         ...                                                ...   \n",
       "116  d000.s116  El tratamiento del vómito debe realizarse siem...   \n",
       "117  d000.s117   ¿Cuáles son los efectos secundarios de Cerenia ?   \n",
       "118  d000.s118  En general , Cerenia fue bien tolerado cuando ...   \n",
       "119  d000.s119  ¿Qué precauciones debe adoptar la persona que ...   \n",
       "120  d000.s120  Cerenia no presenta ningún riesgo especial par...   \n",
       "\n",
       "                             English-Spanish Alignment  \n",
       "0    0-2 1-3 2-4 6-6 7-9 8-8 9-11 10-7 11-12 12-13 ...  \n",
       "1    0-1 1-3 2-4 3-5 4-6 5-7 6-8 6-11 7-8 8-9 9-11 ...  \n",
       "2    0-0 2-1 3-2 4-3 5-4 6-5 8-6 9-7 11-9 12-13 13-...  \n",
       "3    0-0 2-1 3-2 4-3 5-4 6-5 7-6 10-16 11-14 12-17 ...  \n",
       "4                                      0-0 1-1 2-2 3-3  \n",
       "..                                                 ...  \n",
       "116  0-20 2-0 3-1 4-2 5-3 6-4 7-6 8-5 9-8 10-9 11-1...  \n",
       "117                        0-0 1-1 2-2 3-3 5-5 6-6 7-7  \n",
       "118  0-2 1-3 2-0 3-4 4-5 5-6 6-8 7-9 8-10 9-11 11-1...  \n",
       "119  0-0 3-1 5-4 6-5 7-6 8-7 9-8 10-9 11-10 12-11 1...  \n",
       "120               0-0 2-1 3-2 4-7 5-5 6-4 7-6 8-9 9-10  \n",
       "\n",
       "[121 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(aligns))\n",
    "trans_df['English-'+language+' Alignment'] = aligns\n",
    "trans_df.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1399438fa263261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:09.886812Z",
     "start_time": "2024-09-14T08:07:09.733501Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "trans_df.to_csv(ALIGN_SENT_FILE, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6729b5a32fd85f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T00:26:58.685090Z",
     "start_time": "2024-07-20T00:26:58.668497Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7912a9624f4b8438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T00:26:59.328824Z",
     "start_time": "2024-07-20T00:26:59.273476Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# ALIGN TOKENS IN TOKEN FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f494bb7b47b2faa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:10.361932Z",
     "start_time": "2024-09-14T08:07:10.276442Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>BN Synset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>En</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>el</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d000.s000.t000</td>\n",
       "      <td>presente</td>\n",
       "      <td>presente</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>bn:00108977a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d000.s000.t001</td>\n",
       "      <td>documento</td>\n",
       "      <td>documento</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bn:00028015n;bn:00028017n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>se</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token ID      Token      Lemma   POS                  BN Synset\n",
       "0             NaN         En        NaN     X                        NaN\n",
       "1             NaN         el        NaN     X                        NaN\n",
       "2  d000.s000.t000   presente   presente   ADJ               bn:00108977a\n",
       "3  d000.s000.t001  documento  documento  NOUN  bn:00028015n;bn:00028017n\n",
       "4             NaN         se        NaN     X                        NaN"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b05842023dacc1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:10.433980Z",
     "start_time": "2024-09-14T08:07:10.354678Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>BN Synset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>This</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d000.s000.t000</td>\n",
       "      <td>document</td>\n",
       "      <td>document</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bn:00028015n;wiki:document;wn:document%1:10:00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d000.s000.t001</td>\n",
       "      <td>summary</td>\n",
       "      <td>summary</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bn:00075142n;wiki:summary_(law);wn:sum-up%1:10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token ID     Token     Lemma   POS  \\\n",
       "0             NaN      This       NaN     X   \n",
       "1  d000.s000.t000  document  document  NOUN   \n",
       "2             NaN        is        be  VERB   \n",
       "3             NaN         a       NaN     X   \n",
       "4  d000.s000.t001   summary   summary  NOUN   \n",
       "\n",
       "                                           BN Synset  \n",
       "0                                                NaN  \n",
       "1  bn:00028015n;wiki:document;wn:document%1:10:00...  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4  bn:00075142n;wiki:summary_(law);wn:sum-up%1:10...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_tks_df = pd.read_csv(RAW_SENSE_TSV, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "aligned_tks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf87633624b64662",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:10.680530Z",
     "start_time": "2024-09-14T08:07:10.487987Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "aligned_tks_df['Token ID '+tgt_lan] = None\n",
    "aligned_tks_df['Token '+tgt_lan] = None\n",
    "aligned_tks_df['Lemma '+tgt_lan] = None\n",
    "aligned_tks_df['POS '+tgt_lan] = None\n",
    "aligned_tks_df['Sense '+tgt_lan] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96cb23c1328bebd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:10.818745Z",
     "start_time": "2024-09-14T08:07:10.662567Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2759\n"
     ]
    }
   ],
   "source": [
    "aligned_tks_df.head()\n",
    "print(len(aligned_tks_df['Token']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a7cf5efede63ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:10.966484Z",
     "start_time": "2024-09-14T08:07:10.822999Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>English-Spanish Alignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d000.s000</td>\n",
       "      <td>En el presente documento se resume el Informe ...</td>\n",
       "      <td>0-2 1-3 2-4 6-6 7-9 8-8 9-11 10-7 11-12 12-13 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d000.s001</td>\n",
       "      <td>En él se explica cómo el Comité de Medicamento...</td>\n",
       "      <td>0-1 1-3 2-4 3-5 4-6 5-7 6-8 6-11 7-8 8-9 9-11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d000.s002</td>\n",
       "      <td>Si desea más información sobre su enfermedad o...</td>\n",
       "      <td>0-0 2-1 3-2 4-3 5-4 6-5 8-6 9-7 11-9 12-13 13-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d000.s003</td>\n",
       "      <td>Si desea más información sobre el fundamento e...</td>\n",
       "      <td>0-0 2-1 3-2 4-3 5-4 6-5 7-6 10-16 11-14 12-17 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d000.s004</td>\n",
       "      <td>¿Qué es Alimta ?</td>\n",
       "      <td>0-0 1-1 2-2 3-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                           Sentence  \\\n",
       "0  d000.s000  En el presente documento se resume el Informe ...   \n",
       "1  d000.s001  En él se explica cómo el Comité de Medicamento...   \n",
       "2  d000.s002  Si desea más información sobre su enfermedad o...   \n",
       "3  d000.s003  Si desea más información sobre el fundamento e...   \n",
       "4  d000.s004                                   ¿Qué es Alimta ?   \n",
       "\n",
       "                           English-Spanish Alignment  \n",
       "0  0-2 1-3 2-4 6-6 7-9 8-8 9-11 10-7 11-12 12-13 ...  \n",
       "1  0-1 1-3 2-4 3-5 4-6 5-7 6-8 6-11 7-8 8-9 9-11 ...  \n",
       "2  0-0 2-1 3-2 4-3 5-4 6-5 8-6 9-7 11-9 12-13 13-...  \n",
       "3  0-0 2-1 3-2 4-3 5-4 6-5 7-6 10-16 11-14 12-17 ...  \n",
       "4                                    0-0 1-1 2-2 3-3  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d27a48d2ff0f089a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:11.168820Z",
     "start_time": "2024-09-14T08:07:11.029797Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def process_nan(s):\n",
    "  if type(s)!=type(''):\n",
    "    return ''\n",
    "  return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0335593",
   "metadata": {},
   "source": [
    "Run the below alignment if using the English/Original files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d9a577bd69e0209",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:14.404985Z",
     "start_time": "2024-09-14T08:07:11.215237Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 0\n",
      "error 0\n",
      "error 0\n",
      "error 0\n",
      "error 0\n",
      "error 0\n",
      "error 0\n",
      "error 0\n",
      "error 0\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 1\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 2\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 3\n",
      "error 4\n",
      "error 4\n",
      "error 4\n",
      "error 4\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 5\n",
      "error 6\n",
      "error 6\n",
      "error 6\n",
      "error 6\n",
      "error 7\n",
      "error 7\n",
      "error 7\n",
      "error 7\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 8\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 9\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 10\n",
      "error 11\n",
      "error 11\n",
      "error 11\n",
      "error 11\n",
      "error 11\n",
      "error 11\n",
      "error 12\n",
      "error 12\n",
      "error 12\n",
      "error 12\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 13\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 14\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 15\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 16\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 17\n",
      "error 18\n",
      "error 18\n",
      "error 18\n",
      "error 18\n",
      "error 18\n",
      "error 18\n",
      "error 18\n",
      "error 18\n",
      "error 18\n",
      "error 19\n",
      "error 19\n",
      "error 19\n",
      "error 19\n",
      "error 19\n",
      "error 19\n",
      "error 19\n",
      "error 19\n",
      "error 19\n",
      "error 20\n",
      "error 20\n",
      "error 20\n",
      "error 20\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 21\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 22\n",
      "error 23\n",
      "error 23\n",
      "error 23\n",
      "error 23\n",
      "error 23\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 24\n",
      "error 25\n",
      "error 25\n",
      "error 25\n",
      "error 25\n",
      "error 25\n",
      "error 25\n",
      "error 25\n",
      "error 25\n",
      "error 25\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 26\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 27\n",
      "error 28\n",
      "error 28\n",
      "error 28\n",
      "error 28\n",
      "error 28\n",
      "error 28\n",
      "error 28\n",
      "error 28\n",
      "error 28\n",
      "error 29\n",
      "error 29\n",
      "error 29\n",
      "error 29\n",
      "error 29\n",
      "error 29\n",
      "error 29\n",
      "error 30\n",
      "error 30\n",
      "error 30\n",
      "error 30\n",
      "error 30\n",
      "error 30\n",
      "error 30\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 31\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 32\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 33\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 34\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 35\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 36\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 37\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 38\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 39\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 40\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 41\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 42\n",
      "error 43\n",
      "error 43\n",
      "error 43\n",
      "error 43\n",
      "error 43\n",
      "error 43\n",
      "error 43\n",
      "error 43\n",
      "error 43\n",
      "error 43\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 44\n",
      "error 45\n",
      "error 45\n",
      "error 45\n",
      "error 45\n",
      "error 45\n",
      "error 45\n",
      "error 45\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 46\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 47\n",
      "error 48\n",
      "error 48\n",
      "error 48\n",
      "error 48\n",
      "error 48\n",
      "error 48\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 49\n",
      "error 50\n",
      "error 50\n",
      "error 50\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 51\n",
      "error 52\n",
      "error 52\n",
      "error 52\n",
      "error 52\n",
      "error 52\n",
      "error 52\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 53\n",
      "error 54\n",
      "error 54\n",
      "error 54\n",
      "error 54\n",
      "error 54\n",
      "error 54\n",
      "error 54\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 55\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 56\n",
      "error 57\n",
      "error 57\n",
      "error 58\n",
      "error 58\n",
      "error 58\n",
      "error 58\n",
      "error 59\n",
      "error 59\n",
      "error 60\n",
      "error 60\n",
      "error 60\n",
      "error 60\n",
      "error 60\n",
      "error 61\n",
      "error 61\n",
      "error 61\n",
      "error 61\n",
      "error 61\n",
      "error 61\n",
      "error 61\n",
      "error 62\n",
      "error 63\n",
      "error 63\n",
      "error 63\n",
      "error 63\n",
      "error 63\n",
      "error 63\n",
      "error 63\n",
      "error 63\n",
      "error 63\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 64\n",
      "error 65\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 66\n",
      "error 67\n",
      "error 68\n",
      "error 68\n",
      "error 68\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 69\n",
      "error 70\n",
      "error 70\n",
      "error 70\n",
      "error 70\n",
      "error 70\n",
      "error 70\n",
      "error 70\n",
      "error 70\n",
      "error 70\n",
      "error 71\n",
      "error 71\n",
      "error 71\n",
      "error 71\n",
      "error 71\n",
      "error 71\n",
      "error 71\n",
      "error 71\n",
      "error 71\n",
      "error 71\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 72\n",
      "error 73\n",
      "error 73\n",
      "error 73\n",
      "error 73\n",
      "error 73\n",
      "error 73\n",
      "error 74\n",
      "error 74\n",
      "error 74\n",
      "error 74\n",
      "error 74\n",
      "error 74\n",
      "error 75\n",
      "error 75\n",
      "error 75\n",
      "error 75\n",
      "error 76\n",
      "error 76\n",
      "error 76\n",
      "error 76\n",
      "error 76\n",
      "error 76\n",
      "error 76\n",
      "error 76\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 77\n",
      "error 78\n",
      "error 78\n",
      "error 78\n",
      "error 78\n",
      "error 78\n",
      "error 78\n",
      "error 78\n",
      "error 78\n",
      "error 78\n",
      "error 79\n",
      "error 79\n",
      "error 79\n",
      "error 79\n",
      "error 79\n",
      "error 79\n",
      "error 79\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 80\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 81\n",
      "error 82\n",
      "error 82\n",
      "error 82\n",
      "error 82\n",
      "error 82\n",
      "error 82\n",
      "error 82\n",
      "error 82\n",
      "error 82\n",
      "error 82\n",
      "error 83\n",
      "error 83\n",
      "error 83\n",
      "error 83\n",
      "error 83\n",
      "error 83\n",
      "error 83\n",
      "error 83\n",
      "error 83\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 84\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 85\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 86\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 87\n",
      "error 88\n",
      "error 88\n",
      "error 88\n",
      "error 88\n",
      "error 88\n",
      "error 88\n",
      "error 88\n",
      "error 88\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 89\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 90\n",
      "error 91\n",
      "error 91\n",
      "error 91\n",
      "error 91\n",
      "error 91\n",
      "error 91\n",
      "error 91\n",
      "error 91\n",
      "error 91\n",
      "error 91\n",
      "error 92\n",
      "error 92\n",
      "error 92\n",
      "error 92\n",
      "error 92\n",
      "error 92\n",
      "error 92\n",
      "error 92\n",
      "error 92\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 93\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 94\n",
      "error 95\n",
      "error 95\n",
      "error 95\n",
      "error 95\n",
      "error 95\n",
      "error 95\n",
      "error 95\n",
      "error 95\n",
      "error 95\n",
      "error 95\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 96\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 97\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 98\n",
      "error 99\n",
      "error 99\n",
      "error 99\n",
      "error 99\n",
      "error 100\n",
      "error 100\n",
      "error 100\n",
      "error 100\n",
      "error 100\n",
      "error 100\n",
      "error 100\n",
      "error 101\n",
      "error 101\n",
      "error 101\n",
      "error 101\n",
      "error 101\n",
      "error 101\n",
      "error 101\n",
      "error 101\n",
      "error 101\n",
      "error 101\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 102\n",
      "error 103\n",
      "error 103\n",
      "error 103\n",
      "error 104\n",
      "error 104\n",
      "error 104\n",
      "error 104\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 105\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 106\n",
      "error 107\n",
      "error 107\n",
      "error 107\n",
      "error 107\n",
      "error 107\n",
      "error 107\n",
      "error 107\n",
      "error 107\n",
      "error 107\n",
      "error 107\n",
      "error 108\n",
      "error 108\n",
      "error 108\n",
      "error 108\n",
      "error 108\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 109\n",
      "error 110\n",
      "error 110\n",
      "error 110\n",
      "error 110\n",
      "error 110\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 111\n",
      "error 112\n",
      "error 112\n",
      "error 112\n",
      "error 112\n",
      "error 112\n",
      "error 112\n",
      "error 112\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 113\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 114\n",
      "error 115\n",
      "error 115\n",
      "error 115\n",
      "error 115\n",
      "error 115\n",
      "error 115\n",
      "error 115\n",
      "error 115\n",
      "error 115\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 116\n",
      "error 117\n",
      "error 117\n",
      "error 117\n",
      "error 117\n",
      "error 117\n",
      "error 117\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 118\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 119\n",
      "error 120\n",
      "error 120\n",
      "error 120\n",
      "error 120\n",
      "error 120\n",
      "error 120\n"
     ]
    }
   ],
   "source": [
    "count_en = 0\n",
    "sentence_num = 0\n",
    "count_es = 0\n",
    "for i, row in trans_df.iterrows():\n",
    "    # print(row.iloc[0])\n",
    "    sent_i = row.iloc[0]\n",
    "    # print(sent_i)\n",
    "    # print(sent_i)\n",
    "    tgt_sent_i = sent_i\n",
    "    # print(row)\n",
    "    # sent_i = sent_i.replace(\"i\",\"d\")\n",
    "    # tgt_sent = tkns_df.loc[count_es:count_es+len(tgt_sents[sentence_num])]\n",
    "    # en_sent = aligned_tks_df.loc[count_en:count_en+len(en_sents[sentence_num])]\n",
    "    # print(tgt_sent.loc[2])\n",
    "    # print(row)\n",
    "    for alignment in row['English-'+language+' Alignment'].split():\n",
    "        try:\n",
    "            w1, w2 = alignment.split('-')\n",
    "            \n",
    "            en_id = f'{sent_i}.t{int(w1) + 1:03d}'\n",
    "            tgt_id = f'{tgt_sent_i}.t{int(w2) + 1:03d}'\n",
    "            row_en = aligned_tks_df[aligned_tks_df['Token ID'] == en_id]\n",
    "            row_tgt = tkns_df[tkns_df['Token ID'] == tgt_id]\n",
    "            # print(row_tgt)\n",
    "    \n",
    "            # print(aligned_tks_df['Token ID'] )\n",
    "            # print(row_tgt)\n",
    "            # print(row_en.iloc[0]['Token ID '+tgt_lan])\n",
    "            if row_en.iloc[0]['Token ID '+tgt_lan] is not None:\n",
    "                aligned_tks_df.loc[row_en.index, 'Token ID '+tgt_lan] += '➕' + row_tgt.iloc[0]['Token ID']\n",
    "                aligned_tks_df.loc[row_en.index, 'Token '+tgt_lan] += '➕' + row_tgt.iloc[0]['Token']\n",
    "                if aligned_tks_df.loc[row_en.index, 'POS '+tgt_lan].item() != process_nan(row_tgt.iloc[0]['POS']):\n",
    "                    aligned_tks_df.loc[row_en.index, 'POS '+tgt_lan] += '➕' + process_nan(row_tgt.iloc[0]['POS'])\n",
    "                if aligned_tks_df.loc[row_en.index, 'Sense '+tgt_lan].item() != process_nan(row_en.iloc[0]['BN Synset']):\n",
    "                    aligned_tks_df.loc[row_en.index, 'Sense '+tgt_lan] += '➕' + process_nan(str(row_en.iloc[0]['BN Synset']).split(\";\")[0])\n",
    "            else:\n",
    "                # print(str(row_en.iloc[0]['BN Synset']).split(\";\")[0])\n",
    "                # print(row_tgt.iloc[0]['Token ID'])\n",
    "                # print(row_en.index.values)\n",
    "                aligned_tks_df.loc[row_en.index.values[0], 'Token ID '+tgt_lan] = row_tgt.iloc[0]['Token ID']\n",
    "                # print(aligned_tks_df.loc[row_en.index, 'Token ID '+tgt_lan],row_tgt.iloc[0]['Token ID'],'\\\\n\\\\n')\n",
    "        \n",
    "                aligned_tks_df.loc[row_en.index.values[0], 'Token '+tgt_lan] = row_tgt.iloc[0]['Token']\n",
    "                aligned_tks_df.loc[row_en.index.values[0], 'Lemma '+tgt_lan] = row_tgt.iloc[0]['Lemma']\n",
    "                aligned_tks_df.loc[row_en.index.values[0], 'POS '+tgt_lan] = row_tgt.iloc[0]['POS']\n",
    "                aligned_tks_df.loc[row_en.index.values[0], 'Sense '+tgt_lan] = str(row_en.iloc[0]['BN Synset']).split(\";\")[0]\n",
    "                aligned_tks_df.loc[row_en.index.values[0], 'BN Synset'] = str(row_en.iloc[0]['BN Synset']).split(\";\")[0]\n",
    "        except:\n",
    "            print(f\"error {i}\")\n",
    "    # count_en += len(en_sents[sentence_num])\n",
    "    # count_es += len(tgt_sents[sentence_num])\n",
    "    # sentence_num += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aed5746",
   "metadata": {},
   "source": [
    "Run the below for alignment if you are using the provided English/second-sense files and the Spanish or Italian provided files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ae5b20f4241c471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:14.412437Z",
     "start_time": "2024-09-14T08:07:14.406443Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "count_en = 0\n",
    "sentence_num = 0\n",
    "count_es = 0\n",
    "for i, row in trans_df.iterrows():\n",
    "    # print(row.iloc[0])\n",
    "    sent_i = row.iloc[0]\n",
    "    # print(sent_i)\n",
    "    # print(sent_i)\n",
    "    tgt_sent_i = sent_i\n",
    "    # print(row)\n",
    "    # sent_i = sent_i.replace(\"i\",\"d\")\n",
    "    tgt_sent = tkns_df.loc[count_es:count_es+len(tgt_sents[sentence_num])]\n",
    "    en_sent = aligned_tks_df.loc[count_en:count_en+len(en_sents[sentence_num])]\n",
    "    # print(tgt_sent.loc[2])\n",
    "    # print(row)\n",
    "    for alignment in row['English-'+language+' Alignment'].split():\n",
    "        w1, w2 = alignment.split('-')\n",
    "        row_tgt = tgt_sent.loc[count_es+int(w2)]\n",
    "        row_en = en_sent.loc[count_en+int(w1)]\n",
    "        if row_en['Token ID '+tgt_lan] is not None:\n",
    "            if str(aligned_tks_df.loc[count_en+int(w1), 'Token ID '+tgt_lan]) != \"nan\":\n",
    "                aligned_tks_df.loc[count_en+int(w1), 'Token ID '+tgt_lan] += '➕' + str(row_tgt['Token ID'])\n",
    "            else:\n",
    "                aligned_tks_df.loc[count_en+int(w1), 'Token ID '+tgt_lan] = str(row_tgt['Token ID'])\n",
    "            aligned_tks_df.loc[count_en+int(w1), 'Token '+tgt_lan] += '➕' + row_tgt['Token']\n",
    "            if aligned_tks_df.loc[count_en+int(w1), 'POS '+tgt_lan] != process_nan(row_tgt['POS']):\n",
    "                aligned_tks_df.loc[count_en+int(w1), 'POS '+tgt_lan] += '➕' + process_nan(row_tgt['POS'])\n",
    "            if aligned_tks_df.loc[count_en+int(w1), 'Sense '+tgt_lan] != process_nan(row_en['BN Synset']):\n",
    "                if str(aligned_tks_df.loc[count_en+int(w1), 'Sense '+tgt_lan]) != \"nan\":\n",
    "                    aligned_tks_df.loc[count_en+int(w1), 'Sense '+tgt_lan] += '➕' + process_nan(row_en['BN Synset'])\n",
    "        else:\n",
    "            aligned_tks_df.loc[count_en+int(w1), 'Token ID '+tgt_lan] = row_tgt['Token ID']\n",
    "            aligned_tks_df.loc[count_en+int(w1), 'Token '+tgt_lan] = row_tgt['Token']\n",
    "            aligned_tks_df.loc[count_en+int(w1), 'Lemma '+tgt_lan] = row_tgt[\"Lemma\"]\n",
    "            aligned_tks_df.loc[count_en+int(w1), 'POS '+tgt_lan] = row_tgt['POS']\n",
    "            aligned_tks_df.loc[count_en+int(w1), 'Sense '+tgt_lan] = row_en['BN Synset']\n",
    "\n",
    "    count_en += len(en_sents[sentence_num])\n",
    "    count_es += len(tgt_sents[sentence_num])\n",
    "    sentence_num += 1\n",
    "    # print(count_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3762e840ae06d384",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:14.421818Z",
     "start_time": "2024-09-14T08:07:14.417067Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>BN Synset</th>\n",
       "      <th>Token ID ES</th>\n",
       "      <th>Token ES</th>\n",
       "      <th>Lemma ES</th>\n",
       "      <th>POS ES</th>\n",
       "      <th>Sense ES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>This</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d000.s000.t000</td>\n",
       "      <td>presente</td>\n",
       "      <td>presente</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d000.s000.t000</td>\n",
       "      <td>document</td>\n",
       "      <td>document</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bn:00028015n;wiki:document;wn:document%1:10:00...</td>\n",
       "      <td>d000.s000.t001</td>\n",
       "      <td>documento</td>\n",
       "      <td>documento</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bn:00028015n;wiki:document;wn:document%1:10:00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>se</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d000.s000.t001</td>\n",
       "      <td>summary</td>\n",
       "      <td>summary</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bn:00075142n</td>\n",
       "      <td>d000.s000.t003</td>\n",
       "      <td>Informe</td>\n",
       "      <td>informe</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bn:00075142n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-end-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d000.s086.t005</td>\n",
       "      <td>caso</td>\n",
       "      <td>caso</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>For</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>detallado</td>\n",
       "      <td>detallar</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>each</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>d000.s086.t000</td>\n",
       "      <td>country</td>\n",
       "      <td>country</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bn:00011771n;bn:00023235n;wiki:country;wiki:so...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>estos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>bn:00011771n;bn:00023235n;wiki:country;wiki:so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Token ID     Token     Lemma   POS  \\\n",
       "0                NaN      This       NaN     X   \n",
       "1     d000.s000.t000  document  document  NOUN   \n",
       "2                NaN        is        be  VERB   \n",
       "3                NaN         a       NaN     X   \n",
       "4     d000.s000.t001   summary   summary  NOUN   \n",
       "...              ...       ...       ...   ...   \n",
       "1995             NaN     -end-       NaN     X   \n",
       "1996             NaN       For       NaN     X   \n",
       "1997             NaN      each       NaN     X   \n",
       "1998  d000.s086.t000   country   country  NOUN   \n",
       "1999             NaN         ,       NaN     X   \n",
       "\n",
       "                                              BN Synset     Token ID ES  \\\n",
       "0                                                   NaN  d000.s000.t000   \n",
       "1     bn:00028015n;wiki:document;wn:document%1:10:00...  d000.s000.t001   \n",
       "2                                                   NaN             NaN   \n",
       "3                                                   NaN            None   \n",
       "4                                          bn:00075142n  d000.s000.t003   \n",
       "...                                                 ...             ...   \n",
       "1995                                                NaN  d000.s086.t005   \n",
       "1996                                                NaN             NaN   \n",
       "1997                                                NaN            None   \n",
       "1998  bn:00011771n;bn:00023235n;wiki:country;wiki:so...             NaN   \n",
       "1999                                                NaN            None   \n",
       "\n",
       "       Token ES   Lemma ES POS ES  \\\n",
       "0      presente   presente    ADJ   \n",
       "1     documento  documento   NOUN   \n",
       "2            se        NaN      X   \n",
       "3          None       None   None   \n",
       "4       Informe    informe   NOUN   \n",
       "...         ...        ...    ...   \n",
       "1995       caso       caso   NOUN   \n",
       "1996  detallado   detallar   VERB   \n",
       "1997       None       None   None   \n",
       "1998      estos        NaN      X   \n",
       "1999       None       None   None   \n",
       "\n",
       "                                               Sense ES  \n",
       "0                                                   NaN  \n",
       "1     bn:00028015n;wiki:document;wn:document%1:10:00...  \n",
       "2                                                   NaN  \n",
       "3                                                  None  \n",
       "4                                          bn:00075142n  \n",
       "...                                                 ...  \n",
       "1995                                                NaN  \n",
       "1996                                                NaN  \n",
       "1997                                               None  \n",
       "1998  bn:00011771n;bn:00023235n;wiki:country;wiki:so...  \n",
       "1999                                               None  \n",
       "\n",
       "[2000 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aligned_tks_df[]\n",
    "aligned_tks_df.head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5368fae50b58bf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:07:14.468480Z",
     "start_time": "2024-09-14T08:07:14.423068Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "aligned_tks_df.to_csv(ALIGN_TOKEN_FILE, sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
